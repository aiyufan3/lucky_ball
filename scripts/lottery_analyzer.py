#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒè‰²çƒå¼€å¥–æ•°æ®æŠ“å–ä¸åˆ†æè„šæœ¬

âš ï¸  é‡è¦å…è´£å£°æ˜ âš ï¸
1. æœ¬è„šæœ¬ä»…ç”¨äºæŠ€æœ¯å­¦ä¹ å’Œæ•°æ®åˆ†æç ”ç©¶ç›®çš„
2. å½©ç¥¨å¼€å¥–ç»“æœå®Œå…¨éšæœºï¼Œå†å²æ•°æ®æ— æ³•é¢„æµ‹æœªæ¥ç»“æœ
3. æœ¬åˆ†æç»“æœä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆä»»ä½•æŠ•æ³¨å»ºè®®
4. è¯·ç†æ€§è´­å½©ï¼Œé‡åŠ›è€Œè¡Œï¼Œæœªæ»¡18å‘¨å²ç¦æ­¢è´­ä¹°å½©ç¥¨
5. å¼€å‘è€…ä¸æ‰¿æ‹…å› ä½¿ç”¨æœ¬è„šæœ¬äº§ç”Ÿçš„ä»»ä½•æŸå¤±

åŠŸèƒ½ï¼š
1. æŠ“å–ä¸­å›½ç¦åˆ©å½©ç¥¨åŒè‰²çƒå†å²å¼€å¥–æ•°æ®
2. åˆ†æå¼€å¥–å·ç è§„å¾‹
3. åŸºäºç»Ÿè®¡åˆ†æç”Ÿæˆæ¨èå·ç 
"""

import requests
import time
import json
import re
import pandas as pd
import numpy as np
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter, defaultdict
import warnings
import os
import hjson
import random
import torch
import sys
import torch.nn as nn
import torch.optim as optim
from statsmodels.tsa.arima.model import ARIMA
from scipy.stats import entropy as scipy_entropy
warnings.filterwarnings('ignore')

# ===== Calibration defaults (tuned by backtest) =====
# ä¸‰å‘èåˆå…ˆéªŒ: p = Î»1 * p_short + Î»2 * p_weekday + (1-Î»1-Î»2) * p_global
FUSION_L1_SHORT = 0.30     # è¿‘çª—æƒé‡
FUSION_L2_WEEKDAY = 0.20   # å‘¨å‡ æ¡ä»¶æƒé‡
SHORT_WINDOW = 30          # è¿‘çª—é•¿åº¦(æœŸ)
SHRINK_BETA_WEEKDAY = 40.0 # å‘¨å‡ æ¡ä»¶çš„æ”¶ç¼©ç³»æ•°(è¶Šå¤§è¶Šä¿å®ˆ)

# æ¸©åº¦ï¼ˆå¹³æ»‘ï¼Œè¶Šå¤§è¶Šå¹³ï¼‰
TAU_RED = 1.3
TAU_BLUE = 1.5

# ç¨€ç–æ ·æœ¬ä¸‹è°ƒ Alpha çš„é˜ˆå€¼
WEEKDAY_RECENT_WINDOW = 24
WEEKDAY_MIN_COUNT = 8

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class DoubleColorBallAnalyzer:
    """åŒè‰²çƒåˆ†æå™¨"""
    
    def __init__(self):
        self.base_url = "https://www.cwl.gov.cn/ygkj/wqkjgg/"
        self.api_url = "https://www.cwl.gov.cn/cwl_admin/front/cwlkj/search/kjxx/findDrawNotice"
        
        # å¤šä¸ªçœŸå®çš„User-Agentï¼Œç”¨äºè½®æ¢
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'
        ]
    
        self.session = requests.Session()
        self.lottery_data = []

        # ML related
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.red_model = None      # LSTM for red (multi-label)
        self.blue_model = None     # LSTM for blue (single-label)
        self.seq_len = 10
        self.trained = False

        # Reproducibility
        self.seed = 2025
        random.seed(self.seed)
        np.random.seed(self.seed)
        torch.manual_seed(self.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(self.seed)

        # é…ç½®session
        self._setup_session()
        
    def _setup_session(self):
        """é…ç½®sessionçš„åŸºæœ¬è®¾ç½®"""
        # è®¾ç½®è¿æ¥æ± 
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=10,
            pool_maxsize=20,
            max_retries=3
        )
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
        
        # è®¾ç½®åŸºæœ¬headers
        self._update_headers()
    
    def _update_headers(self):
        """æ›´æ–°è¯·æ±‚å¤´ï¼Œä½¿ç”¨éšæœºUser-Agent"""
        user_agent = random.choice(self.user_agents)
        
        headers = {
            'User-Agent': user_agent,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
        
        self.session.headers.update(headers)
        print(f"ğŸ”„ æ›´æ–°User-Agent: {user_agent[:50]}...")

    def _sorted_data(self, descending=True):
        """Return lottery_data sorted by (date, period)."""
        keyfn = lambda r: (r.get('date', ''), r.get('period', ''))
        return sorted(self.lottery_data, key=keyfn, reverse=descending)

    # ===== Weekday helpers =====
    def _weekday_from_date(self, date_str):
        """Return weekday index for 'YYYY-MM-DD' (Mon=0..Sun=6)."""
        try:
            return datetime.strptime(date_str, "%Y-%m-%d").weekday()
        except Exception:
            return None

    def _next_draw_weekday(self, now=None):
        """Return next draw's weekday index based on Tue/Thu/Sun schedule (Mon=0..Sun=6)."""
        draw_days = {1, 3, 6}  # Tue, Thu, Sun
        if now is None:
            # use UTC+8 for CN lottery
            now = datetime.utcnow() + timedelta(hours=8)
        wd = now.weekday()
        for offset in range(0, 8):  # within next week
            cand = (wd + offset) % 7
            if cand in draw_days and offset > 0:  # the *next* draw day from now
                return cand
        # fallback
        return 1  # Tue

    def _weekday_features(self, wd):
        """Cyclical + one-hot(Tue/Thu/Sun): returns [sin, cos, is_tue, is_thu, is_sun]."""
        if wd is None:
            return np.zeros(5, dtype=np.float32)
        angle = 2.0 * np.pi * (wd / 7.0)
        sinv = np.sin(angle); cosv = np.cos(angle)
        is_tue = 1.0 if wd == 1 else 0.0
        is_thu = 1.0 if wd == 3 else 0.0
        is_sun = 1.0 if wd == 6 else 0.0
        return np.array([sinv, cosv, is_tue, is_thu, is_sun], dtype=np.float32)

    def get_max_pages(self):
        """è·å–çœŸå®çš„æœ€å¤§é¡µç ï¼Œå¢å¼ºé”™è¯¯å¤„ç†"""
        print("æ­£åœ¨è·å–æœ€å¤§é¡µç ...")
        
        max_retries = 5
        base_delay = 2
        
        for attempt in range(max_retries):
            try:
                # æ¯æ¬¡å°è¯•éƒ½æ›´æ–°headers
                self._update_headers()
                
                # å…ˆè·å–ç¬¬ä¸€é¡µæ•°æ®æ¥ç¡®å®šæ€»æ•°
                params = {
                    'name': 'ssq',
                    'pageNo': 1,
                    'pageSize': 30,
                    'systemType': 'PC'
                }
                
                # æ·»åŠ éšæœºå»¶æ—¶
                # if attempt > 0:
                #     delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                #     print(f"â³ ç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                #     time.sleep(delay)
                # else:
                #     time.sleep(random.uniform(0, 1))  # åˆå§‹éšæœºå»¶æ—¶
                
                print(f"ğŸŒ æ­£åœ¨è¯·æ±‚API... (å°è¯• {attempt + 1}/{max_retries})")
                response = self.session.get(self.api_url, params=params, timeout=30)
                
                print(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
                response.raise_for_status()
                
                data = response.json()
                print(f"ğŸ“Š APIå“åº”: state={data.get('state')}, message={data.get('message')}")
                
                if data.get('state') != 0:
                    print(f"âŒ APIè¿”å›é”™è¯¯: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    if attempt < max_retries - 1:
                        continue
                    else:
                        return 100  # é»˜è®¤è¿”å›100é¡µ
                
                # å°è¯•è·å–æ€»è®°å½•æ•°
                total_count = data.get('total', 0)
                if total_count > 0:
                    max_pages = (total_count + 29) // 30  # å‘ä¸Šå–æ•´
                    print(f"âœ… å‘ç°æ€»å…± {total_count} æ¡è®°å½•ï¼Œéœ€è¦æŠ“å– {max_pages} é¡µ")
                    return max_pages
                
                # å¦‚æœæ— æ³•è·å–æ€»æ•°ï¼Œé€šè¿‡è¯•æ¢æ–¹å¼ç¡®å®šæœ€å¤§é¡µç 
                print("æ— æ³•è·å–æ€»è®°å½•æ•°ï¼Œæ­£åœ¨è¯•æ¢æœ€å¤§é¡µç ...")
                page = 1
                while page <= 200:  # è®¾ç½®ä¸Šé™é˜²æ­¢æ— é™å¾ªç¯
                    params['pageNo'] = page
                    response = self.session.get(self.api_url, params=params, timeout=30)
                    data = response.json()
                    
                    if data.get('state') != 0 or not data.get('result'):
                        break
                    
                    page += 10  # æ¯æ¬¡è·³è·ƒ10é¡µå¿«é€Ÿè¯•æ¢
                    time.sleep(0.2)
                
                # ç²¾ç¡®å®šä½æœ€å¤§é¡µç 
                start = max(1, page - 10)
                end = page
                
                for precise_page in range(start, end + 1):
                    params['pageNo'] = precise_page
                    response = self.session.get(self.api_url, params=params, timeout=30)
                    data = response.json()
                    
                    if data.get('state') != 0 or not data.get('result'):
                        max_pages = precise_page - 1
                        print(f"âœ… é€šè¿‡è¯•æ¢ç¡®å®šæœ€å¤§é¡µç ä¸º {max_pages}")
                        return max_pages
                    
                    time.sleep(0.1)
                
                return max(1, page - 1)
                
            except requests.exceptions.Timeout:
                print(f"â° è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
            except requests.exceptions.ConnectionError:
                print(f"ğŸ”Œ è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries})")
            except requests.exceptions.HTTPError as e:
                print(f"ğŸŒ HTTPé”™è¯¯: {e} (å°è¯• {attempt + 1}/{max_retries})")
            except Exception as e:
                print(f"âŒ è·å–æœ€å¤§é¡µç æ—¶å‡ºé”™: {e} (å°è¯• {attempt + 1}/{max_retries})")
            
            if attempt < max_retries - 1:
                print("ğŸ”„ å‡†å¤‡é‡è¯•...")
        
        print("âš ï¸  æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é¡µæ•° 100")
        return 100
    
    def fetch_lottery_data(self, max_pages=10):
        """æŠ“å–åŒè‰²çƒå¼€å¥–æ•°æ®ï¼Œå¢å¼ºé”™è¯¯å¤„ç†"""
        print("å¼€å§‹æŠ“å–åŒè‰²çƒå¼€å¥–æ•°æ®...")
        
        consecutive_failures = 0
        max_consecutive_failures = 5
        successful_pages = 0
        
        for page in range(1, max_pages + 1):
            print(f"ğŸ“„ æ­£åœ¨æŠ“å–ç¬¬ {page} é¡µæ•°æ®...")
            
            # é‡è¯•æœºåˆ¶
            max_retries = 5
            retry_count = 0
            success = False
            base_delay = 1
            
            while retry_count < max_retries and not success:
                try:
                    # æ¯éš”å‡ æ¬¡è¯·æ±‚æ›´æ–°headers
                    if page % 5 == 1 or retry_count > 0:
                        self._update_headers()
                    
                    # APIå‚æ•°
                    params = {
                        'name': 'ssq',  # åŒè‰²çƒ
                        'pageNo': page,
                        'pageSize': 30,
                        'systemType': 'PC'
                    }
                    
                    # è®¡ç®—å»¶æ—¶
                    # if retry_count > 0:
                    #     # æŒ‡æ•°é€€é¿å»¶æ—¶ï¼ŒåŠ ä¸Šéšæœºå› å­
                    #     delay = min(base_delay * (2 ** retry_count), 15) + random.uniform(0, 2)
                    #     print(f"â³ ç¬¬ {retry_count + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    #     time.sleep(delay)
                    # else:
                    #     # æ­£å¸¸å»¶æ—¶ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                    #     delay = random.uniform(1, 2)  # 1-2ç§’éšæœºå»¶æ—¶
                    #     time.sleep(delay)
                    
                    print(f"ğŸŒ å‘é€è¯·æ±‚åˆ°API... (é¡µé¢ {page}, å°è¯• {retry_count + 1})")
                    response = self.session.get(self.api_url, params=params, timeout=30)
                    
                    print(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
                    response.raise_for_status()
                    
                    # è§£æJSONå“åº”
                    data = response.json()
                    print(f"ğŸ“Š APIå“åº”è§£æ: state={data.get('state')}")
                    
                    if data.get('state') != 0:
                        print(f"âŒ APIè¿”å›é”™è¯¯: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                        retry_count += 1
                        continue
                    
                    results = data.get('result', [])
                    if not results:
                        print(f"ğŸ“­ ç¬¬ {page} é¡µæ— æ•°æ®")
                        break
                    
                    print(f"âœ… ç¬¬ {page} é¡µè·å–åˆ° {len(results)} æ¡è®°å½•")
                    consecutive_failures = 0  # é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°
                    successful_pages += 1
                    
                    for item in results:
                        try:
                            # è§£ææœŸå·
                            period = item.get('code', '')
                            
                            # è§£æå¼€å¥–æ—¥æœŸ
                            date_str = item.get('date', '')
                            # æå–æ—¥æœŸéƒ¨åˆ†ï¼Œå»é™¤æ˜ŸæœŸä¿¡æ¯
                            date_match = re.search(r'(\d{4}-\d{2}-\d{2})', date_str)
                            if not date_match:
                                continue
                            draw_date = date_match.group(1)
                            
                            # è§£æçº¢çƒå·ç ï¼ˆé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ï¼‰
                            red_str = item.get('red', '')
                            if not red_str:
                                continue
                            red_balls = [int(x.strip()) for x in red_str.split(',')]
                            
                            # è§£æè“çƒå·ç 
                            blue_str = item.get('blue', '')
                            if not blue_str:
                                continue
                            blue_ball = int(blue_str)
                            
                            # è§£æå…¶ä»–ä¿¡æ¯
                            sales_amount = self._parse_number(item.get('sales', '0'))
                            pool_amount = self._parse_number(item.get('poolmoney', '0'))
                            
                            # è§£æå¥–çº§ä¿¡æ¯
                            prizegrades = item.get('prizegrades', [])
                            first_prize_count = 0
                            first_prize_amount = 0
                            second_prize_count = 0
                            second_prize_amount = 0
                            
                            for grade in prizegrades:
                                if grade.get('type') == 1:  # ä¸€ç­‰å¥–
                                    first_prize_count = self._parse_number(grade.get('typenum', '0'))
                                    first_prize_amount = self._parse_number(grade.get('typemoney', '0'))
                                elif grade.get('type') == 2:  # äºŒç­‰å¥–
                                    second_prize_count = self._parse_number(grade.get('typenum', '0'))
                                    second_prize_amount = self._parse_number(grade.get('typemoney', '0'))
                            
                            # å­˜å‚¨æ•°æ®
                            lottery_record = {
                                'period': period,
                                'date': draw_date,
                                'red_balls': red_balls,
                                'blue_ball': blue_ball,
                                'first_prize_count': first_prize_count,
                                'first_prize_amount': first_prize_amount,
                                'second_prize_count': second_prize_count,
                                'second_prize_amount': second_prize_amount,
                                'sales_amount': sales_amount,
                                'pool_amount': pool_amount
                            }
                            
                            self.lottery_data.append(lottery_record)
                            
                        except Exception as e:
                            print(f"âš ï¸  è§£æè®°å½•æ—¶å‡ºé”™: {e}")
                            continue
                    
                    success = True  # æ ‡è®°æˆåŠŸ
                    
                except requests.exceptions.Timeout:
                    print(f"â° ç½‘ç»œè¶…æ—¶ (é¡µé¢ {page}, å°è¯• {retry_count + 1})")
                    retry_count += 1
                except requests.exceptions.ConnectionError:
                    print(f"ğŸ”Œ è¿æ¥é”™è¯¯ (é¡µé¢ {page}, å°è¯• {retry_count + 1})")
                    retry_count += 1
                except requests.exceptions.HTTPError as e:
                    print(f"ğŸŒ HTTPé”™è¯¯: {e} (é¡µé¢ {page}, å°è¯• {retry_count + 1})")
                    retry_count += 1
                except Exception as e:
                    print(f"âŒ æŠ“å–ç¬¬ {page} é¡µæ—¶å‡ºé”™: {e} (å°è¯• {retry_count + 1})")
                    retry_count += 1
                
                if retry_count >= max_retries:
                    consecutive_failures += 1
                    print(f"ğŸ’¥ ç¬¬ {page} é¡µé‡è¯• {max_retries} æ¬¡åä»ç„¶å¤±è´¥ï¼Œè·³è¿‡æ­¤é¡µ")
                    break
            
            # å¦‚æœè¿ç»­å¤±è´¥å¤ªå¤šæ¬¡ï¼Œåœæ­¢æŠ“å–
            if consecutive_failures >= max_consecutive_failures:
                print(f"ğŸ›‘ è¿ç»­ {max_consecutive_failures} é¡µå¤±è´¥ï¼Œåœæ­¢æŠ“å–ä»¥é¿å…è¢«å°ç¦")
                break
        
        print(f"ğŸ‰ æ•°æ®æŠ“å–å®Œæˆï¼æˆåŠŸæŠ“å– {successful_pages} é¡µï¼Œå…±è·å– {len(self.lottery_data)} æœŸå¼€å¥–æ•°æ®")
        
        # å¦‚æœè·å–çš„æ•°æ®å¤ªå°‘ï¼Œç»™å‡ºè­¦å‘Š
        if len(self.lottery_data) < 100:
            print(f"âš ï¸  è·å–çš„æ•°æ®è¾ƒå°‘ ({len(self.lottery_data)} æœŸ)ï¼Œå¯èƒ½å­˜åœ¨ç½‘ç»œé—®é¢˜")
        
        return self.lottery_data
    
    def _parse_number(self, text):
        """è§£ææ•°å­—ï¼Œç§»é™¤é€—å·ç­‰æ ¼å¼ç¬¦å·"""
        if not text or text == '-':
            return 0
        # ç§»é™¤é€—å·ã€ï¿¥ç¬¦å·ç­‰
        cleaned = re.sub(r'[,ï¿¥Â¥å…ƒ]', '', str(text))
        try:
            return int(float(cleaned))
        except:
            return 0
    
    def save_data(self, filename="data/lottery_data.json"):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.lottery_data, f, ensure_ascii=False, indent=2)
        print(f"æ•°æ®å·²ä¿å­˜åˆ° {filename}")
    
    def load_data(self, filename="data/lottery_data.json"):
        """ä»æ–‡ä»¶åŠ è½½æ•°æ®"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                self.lottery_data = json.load(f)
            print(f"ä» {filename} åŠ è½½äº† {len(self.lottery_data)} æœŸæ•°æ®")
            return True
        except FileNotFoundError:
            print(f"æ–‡ä»¶ {filename} ä¸å­˜åœ¨")
            return False
    
    def analyze_frequency(self):
        """åˆ†æå·ç å‡ºç°é¢‘ç‡"""
        print("\n=== å·ç é¢‘ç‡åˆ†æ ===")
        
        # çº¢çƒé¢‘ç‡åˆ†æ
        red_counter = Counter()
        blue_counter = Counter()
        
        for record in self.lottery_data:
            for red in record['red_balls']:
                red_counter[red] += 1
            blue_counter[record['blue_ball']] += 1
        
        # çº¢çƒé¢‘ç‡æ’åº
        red_freq = sorted(red_counter.items(), key=lambda x: x[1], reverse=True)
        print("\nçº¢çƒå‡ºç°é¢‘ç‡æ’è¡Œæ¦œï¼ˆå‰10ï¼‰ï¼š")
        for i, (num, count) in enumerate(red_freq[:10], 1):
            percentage = (count / len(self.lottery_data)) * 100
            print(f"{i:2d}. å·ç  {num:2d}: å‡ºç° {count:3d} æ¬¡ ({percentage:.1f}%)")
        
        # è“çƒé¢‘ç‡æ’åº
        blue_freq = sorted(blue_counter.items(), key=lambda x: x[1], reverse=True)
        print("\nè“çƒå‡ºç°é¢‘ç‡æ’è¡Œæ¦œï¼ˆå‰10ï¼‰ï¼š")
        for i, (num, count) in enumerate(blue_freq[:10], 1):
            percentage = (count / len(self.lottery_data)) * 100
            print(f"{i:2d}. å·ç  {num:2d}: å‡ºç° {count:3d} æ¬¡ ({percentage:.1f}%)")
        
        return red_counter, blue_counter
    
    # -------------------- ML helpers & models --------------------
    class _SeqPredictor(nn.Module):
        """Generic LSTM predictor that emits a single-step prediction."""
        def __init__(self, input_size, hidden_size, output_size, output_type="sigmoid", dropout=0.2):
            super().__init__()
            self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)
            self.dropout = nn.Dropout(p=dropout)
            self.head = nn.Linear(hidden_size, output_size)
            self.output_type = output_type

        def forward(self, x):
            # x: (B, T, F)
            out, _ = self.lstm(x)
            last = out[:, -1, :]
            last = self.dropout(last)
            logits = self.head(last)
            if self.output_type == "sigmoid":
                return logits, torch.sigmoid(logits)
            elif self.output_type == "softmax":
                return logits, torch.softmax(logits, dim=-1)
            else:
                return logits, logits
            
    def _engineered_features(self, reds, weekday):
        """
        Hand-crafted features from a draw:
        - sum (min 21, max 183) -> min-max normalized
        - span (max-min), max 32 -> normalized to [0,1]
        - odd_ratio, even_ratio
        - weekday cyclic (sin, cos) + one-hot(Tue/Thu/Sun)
        Returns a (9,) float32 vector.
        """
        s = sum(reds)
        s_norm = (s - 21.0) / 162.0  # 183-21=162
        span = max(reds) - min(reds)
        span_norm = span / 32.0
        odd = sum(1 for r in reds if r % 2 == 1)
        even = 6 - odd
        wdf = self._weekday_features(weekday)  # (5,)
        base = np.array([s_norm, span_norm, odd / 6.0, even / 6.0], dtype=np.float32)
        return np.concatenate([base, wdf], axis=0)
    
    def _onehot_multi(self, reds, blue, weekday):
        """
        Convert a draw to multi-hot (33) + one-hot (16) + engineered(9) -> (58,)
        """
        red_vec = np.zeros(33, dtype=np.float32)
        for r in reds:
            if 1 <= r <= 33:
                red_vec[r-1] = 1.0
        blue_vec = np.zeros(16, dtype=np.float32)
        if 1 <= blue <= 16:
            blue_vec[blue-1] = 1.0
        feats = self._engineered_features(reds, weekday)
        return np.concatenate([red_vec, blue_vec, feats], axis=0)

    def _build_sequence_dataset(self, seq_len=10):
        """
        Build X (N, seq_len, 58), y_red (N,33), y_blue (N,)
        Newest-first in memory -> sort to oldest-first for sequences.
        """
        if not self.lottery_data or len(self.lottery_data) <= seq_len:
            return None
        data_sorted = sorted(self.lottery_data, key=lambda r: (r["date"], r["period"]))
        feats = [self._onehot_multi(r["red_balls"], r["blue_ball"], self._weekday_from_date(r["date"])) for r in data_sorted]
        X, y_red, y_blue = [], [], []
        for i in range(seq_len, len(feats)):
            X.append(np.stack(feats[i-seq_len:i], axis=0))  # (seq_len,58)
            red_vec = np.zeros(33, dtype=np.float32)
            for rr in data_sorted[i]["red_balls"]:
                red_vec[rr-1] = 1.0
            y_red.append(red_vec)
            y_blue.append(int(data_sorted[i]["blue_ball"]) - 1)
        X = np.stack(X, axis=0).astype(np.float32)
        y_red = np.stack(y_red, axis=0).astype(np.float32)
        y_blue = np.array(y_blue, dtype=np.int64)
        return X, y_red, y_blue
    
    def _sym_kl(self, p, q):
        p = np.clip(np.asarray(p, dtype=np.float64), 1e-12, 1.0)
        q = np.clip(np.asarray(q, dtype=np.float64), 1e-12, 1.0)
        kl_pq = np.sum(p * np.log(p / q))
        kl_qp = np.sum(q * np.log(q / p))
        return float(kl_pq + kl_qp)
    
    def time_decay_weights(self, n_rows, half_life=60):
        """Exponential time-decay weights old->new."""
        idx = np.arange(n_rows)
        lam = np.log(2) / max(1, half_life)
        return np.exp(lam * (idx - n_rows + 1))

    def compute_marginal_probs(self, decay_half_life=60, cond_weekday=None, shrink_beta=20.0):
        """
        Time-decayed marginal probabilities for red(33) and blue(16).
        Optionally condition on weekday (Mon=0..Sun=6) with shrinkage.
        """
        if not self.lottery_data:
            return np.ones(33)/33.0, np.ones(16)/16.0
        data_sorted = sorted(self.lottery_data, key=lambda r: (r["date"], r["period"]))
        reds_list = [r["red_balls"] for r in data_sorted]
        blues_list = [r["blue_ball"] for r in data_sorted]
        wdays = [self._weekday_from_date(r["date"]) for r in data_sorted]
        n = len(reds_list)
        w = self.time_decay_weights(n, half_life=decay_half_life)

        # global counts
        red_counts_g = np.zeros(33, dtype=np.float64)
        blue_counts_g = np.zeros(16, dtype=np.float64)
        for balls, wb, weight in zip(reds_list, blues_list, w):
            for b in balls:
                red_counts_g[b-1] += weight
            blue_counts_g[wb-1] += weight
        pr_g = red_counts_g / red_counts_g.sum() if red_counts_g.sum() > 0 else np.ones(33)/33.0
        pb_g = blue_counts_g / blue_counts_g.sum() if blue_counts_g.sum() > 0 else np.ones(16)/16.0

        if cond_weekday is None:
            return pr_g.astype(np.float32), pb_g.astype(np.float32)

        # weekday-conditional counts
        red_counts_c = np.zeros(33, dtype=np.float64)
        blue_counts_c = np.zeros(16, dtype=np.float64)
        n_c = 0.0
        for balls, wb, wd_i, weight in zip(reds_list, blues_list, wdays, w):
            if wd_i == cond_weekday:
                n_c += 1.0
                for b in balls:
                    red_counts_c[b-1] += weight
                blue_counts_c[wb-1] += weight
        # if too few samples, fall back to global via shrinkage
        pr_c = red_counts_c / red_counts_c.sum() if red_counts_c.sum() > 0 else pr_g
        pb_c = blue_counts_c / blue_counts_c.sum() if blue_counts_c.sum() > 0 else pb_g
        mix = n_c / (n_c + shrink_beta)
        pr = mix * pr_c + (1.0 - mix) * pr_g
        pb = mix * pb_c + (1.0 - mix) * pb_g
        return pr.astype(np.float32), pb.astype(np.float32)
    def _marginal_probs_window(self, decay_half_life=60, cond_weekday=None, window=None, shrink_beta=SHRINK_BETA_WEEKDAY):
        """åœ¨çª—å£å†…è®¡ç®—æ—¶é—´è¡°å‡è¾¹é™…æ¦‚ç‡ï¼›è‹¥ window ä¸º None åˆ™ç­‰åŒå…¨é‡ã€‚"""
        data_sorted = sorted(self.lottery_data, key=lambda r: (r["date"], r["period"]))
        if window is not None and window > 0:
            data_sorted = data_sorted[-int(window):]
        # ä¸´æ—¶åˆ†æå™¨ä»¥å¤ç”¨ç°æœ‰é€»è¾‘
        tmp = DoubleColorBallAnalyzer()
        tmp.lottery_data = list(data_sorted)
        return tmp.compute_marginal_probs(decay_half_life=decay_half_life, cond_weekday=cond_weekday, shrink_beta=shrink_beta)

    def _three_way_fused_prior(self, decay_half_life=60):
        """è¿”å›(çº¢,è“)çš„ä¸‰å‘èåˆå…ˆéªŒ: è¿‘çª—/å‘¨å‡ /å…¨å±€ã€‚"""
        target_wd = self._next_draw_weekday()
        # è¿‘çª— + å‘¨å‡ 
        pr_short, pb_short = self._marginal_probs_window(decay_half_life=decay_half_life, cond_weekday=target_wd, window=SHORT_WINDOW, shrink_beta=SHRINK_BETA_WEEKDAY)
        # å…¨é‡ + å‘¨å‡ 
        pr_wd, pb_wd = self.compute_marginal_probs(decay_half_life=decay_half_life, cond_weekday=target_wd, shrink_beta=SHRINK_BETA_WEEKDAY)
        # å…¨é‡(ä¸æŒ‰å‘¨å‡ )
        pr_g, pb_g = self.compute_marginal_probs(decay_half_life=decay_half_life, cond_weekday=None, shrink_beta=SHRINK_BETA_WEEKDAY)
        # èåˆ
        lam1 = float(np.clip(FUSION_L1_SHORT, 0.0, 1.0))
        lam2 = float(np.clip(FUSION_L2_WEEKDAY, 0.0, 1.0))
        lam3 = max(0.0, 1.0 - lam1 - lam2)
        pr = lam1 * pr_short + lam2 * pr_wd + lam3 * pr_g
        pb = lam1 * pb_short + lam2 * pb_wd + lam3 * pb_g
        pr = (pr / pr.sum()).astype(np.float32)
        pb = (pb / pb.sum()).astype(np.float32)
        return pr, pb
    def _temp_smooth(self, p, tau=1.3):
        """Temperature smoothing for probability vectors (tau>1 => softer)."""
        p = np.clip(np.asarray(p, dtype=np.float64), 1e-12, 1.0)
        logp = np.log(p)
        q = np.exp(logp / max(1e-6, tau))
        return (q / q.sum()).astype(np.float32)

    def compute_entropy(self, probs):
        """Shannon entropy (bits)."""
        p = np.clip(np.asarray(probs, dtype=np.float64), 1e-12, 1.0)
        return float(scipy_entropy(p, base=2))

    def _recent_hot_blues(self, window=10, min_count=2):
        """è“çƒåœ¨æœ€è¿‘ window æœŸä¸­å‡ºç°è‡³å°‘ min_count æ¬¡çš„å·ç """
        if not self.lottery_data:
            return []
        data_sorted = self._sorted_data(descending=True)
        recent = data_sorted[:max(1, window)]
        cnt = Counter([r['blue_ball'] for r in recent])
        hots = [b for b, c in cnt.items() if c >= max(1, min_count)]
        return sorted(hots)

    def train_ml_model(self, seq_len=10, epochs=5, lr=1e-3, hidden_size=64, dropout=0.2):
        """
        Train two LSTM predictors:
        - red: multi-label (33 outputs, BCEWithLogitsLoss)
        - blue: single-label (16 outputs, CrossEntropyLoss)
        """
        self.seq_len = seq_len
        ds = self._build_sequence_dataset(seq_len=seq_len)
        if ds is None:
            print("æ•°æ®ä¸è¶³ï¼Œè·³è¿‡æ¨¡å‹è®­ç»ƒã€‚")
            self.trained = False
            return
        X, y_red, y_blue = ds
        X_t = torch.from_numpy(X).to(self.device)
        y_red_t = torch.from_numpy(y_red).to(self.device)
        y_blue_t = torch.from_numpy(y_blue).to(self.device)

        input_size = X_t.shape[-1]
        self.red_model  = self._SeqPredictor(input_size, hidden_size, 33, output_type="sigmoid", dropout=dropout).to(self.device)
        self.blue_model = self._SeqPredictor(input_size, hidden_size, 16, output_type="softmax",  dropout=dropout).to(self.device)

        red_criterion = nn.BCEWithLogitsLoss()
        blue_criterion = nn.CrossEntropyLoss()
        red_opt = optim.Adam(self.red_model.parameters(), lr=lr)
        blue_opt = optim.Adam(self.blue_model.parameters(), lr=lr)

        batch_size = min(128, X_t.shape[0])
        num_batches = int(np.ceil(X_t.shape[0] / batch_size))

        self.red_model.train(); self.blue_model.train()
        for ep in range(epochs):
            perm = torch.randperm(X_t.shape[0])
            X_t = X_t[perm]; y_red_t = y_red_t[perm]; y_blue_t = y_blue_t[perm]
            red_loss_sum = 0.0; blue_loss_sum = 0.0
            for bi in range(num_batches):
                s = bi * batch_size; e = min((bi+1) * batch_size, X_t.shape[0])
                xb = X_t[s:e]; yrb = y_red_t[s:e]; ybb = y_blue_t[s:e]

                red_opt.zero_grad()
                red_logits, _ = self.red_model(xb)
                loss_red = red_criterion(red_logits, yrb)
                loss_red.backward(); red_opt.step()

                blue_opt.zero_grad()
                blue_logits, _ = self.blue_model(xb)
                loss_blue = blue_criterion(blue_logits, ybb)
                loss_blue.backward(); blue_opt.step()

                red_loss_sum += loss_red.item(); blue_loss_sum += loss_blue.item()
            print(f"[LSTM] epoch {ep+1}/{epochs} red_loss={red_loss_sum/num_batches:.4f} blue_loss={blue_loss_sum/num_batches:.4f}")

        self.trained = True

    def predict_next_probabilities(self, blend_alpha="auto", decay_half_life=60):
        """
        Next-step probabilities for red(33) and blue(16).
        If blend_alpha == "auto": tune alpha by comparing ML vs. marginal distributions
        using symmetric KL divergence (smaller divergence -> larger alpha).
        """
        # ä¸‰å‘èåˆå…ˆéªŒï¼ˆçŸ­çª—/å‘¨å‡ /å…¨å±€ï¼‰
        p_marg_red, p_marg_blue = self._three_way_fused_prior(decay_half_life=decay_half_life)
        if not self.trained:
            print("æ¨¡å‹æœªè®­ç»ƒï¼Œä½¿ç”¨ä¸‰å‘èåˆå…ˆéªŒä½œä¸ºæ¦‚ç‡ã€‚")
            return p_marg_red, p_marg_blue

        ds = self._build_sequence_dataset(seq_len=self.seq_len)
        if ds is None:
            return p_marg_red, p_marg_blue
        X, _, _ = ds
        last_seq = torch.from_numpy(X[-1:]).to(self.device)

        self.red_model.eval(); self.blue_model.eval()
        with torch.no_grad():
            _, p_red_ml = self.red_model(last_seq)   # (1,33)
            _, p_blue_ml = self.blue_model(last_seq) # (1,16)
        p_red_ml = p_red_ml.squeeze(0).cpu().numpy()
        p_blue_ml = p_blue_ml.squeeze(0).cpu().numpy()

        # å½’ä¸€åŒ– + æ¸©åº¦å¹³æ»‘ï¼ˆè“çƒæ›´ä¿å®ˆï¼‰
        p_red_ml = p_red_ml / (p_red_ml.sum() + 1e-12)
        tau_blue = TAU_BLUE + (0.1 if float(np.max(p_blue_ml)) > 0.18 else 0.0)
        p_red_ml  = self._temp_smooth(p_red_ml, tau=TAU_RED)
        p_blue_ml = self._temp_smooth(p_blue_ml, tau=tau_blue)

        # è‡ªé€‚åº” alphaï¼ˆåŸºäºå¯¹å…ˆéªŒçš„åç¦»ï¼‰
        if blend_alpha == "auto":
            d_red = self._sym_kl(p_red_ml, p_marg_red)
            d_blue = self._sym_kl(p_blue_ml, p_marg_blue)
            d = 0.7 * d_red + 0.3 * d_blue
            alpha = 1.0 / (1.0 + 4.0 * d)
            alpha = float(np.clip(alpha, 0.20, 0.60))
            # è‹¥æœ€è¿‘ WEEKDAY_RECENT_WINDOW æœŸå†…ç›®æ ‡å‘¨å‡ æ ·æœ¬è¿‡å°‘ï¼Œåˆ™é™ä½è‡ªä¿¡
            data_sorted = sorted(self.lottery_data, key=lambda r: (r["date"], r["period"]))
            recent = data_sorted[-int(min(WEEKDAY_RECENT_WINDOW, len(data_sorted))):]
            n_wd = sum(1 for r in recent if self._weekday_from_date(r["date"]) == self._next_draw_weekday())
            if n_wd < WEEKDAY_MIN_COUNT:
                alpha *= 0.85
            print(f"ğŸ”§ è‡ªé€‚åº”èåˆç³»æ•° alpha={alpha:.3f} (ä¸‰å‘å…ˆéªŒ)")
        else:
            alpha = float(blend_alpha)

        p_red = alpha * p_red_ml + (1.0 - alpha) * p_marg_red
        p_blue = alpha * p_blue_ml + (1.0 - alpha) * p_marg_blue
        p_red = p_red / p_red.sum(); p_blue = p_blue / p_blue.sum()
        return p_red.astype(np.float32), p_blue.astype(np.float32)

    def _arima_sum_forecast(self, horizon=1):
            """
            ARIMA on red sums to get (mu, low, high) for next draw.
            """
            try:
                series = [sum(r["red_balls"]) for r in sorted(self.lottery_data, key=lambda r: (r["date"], r["period"]))]
                if len(series) < 30:
                    mu = np.mean(series)
                    return float(mu), float(mu-20), float(mu+20)
                model = ARIMA(series, order=(2,1,2))
                model_fit = model.fit()
                pred = model_fit.get_forecast(steps=horizon)
                # predicted_mean can be ndarray/Series depending on input; coerce to ndarray
                mu = float(np.asanyarray(pred.predicted_mean)[-1])
                ci = pred.conf_int(alpha=0.20)  # 80%
                try:
                    # pandas DataFrame case
                    low = float(ci.iloc[-1, 0]); high = float(ci.iloc[-1, 1])
                except AttributeError:
                    # numpy ndarray case: shape (steps, 2)
                    low = float(ci[-1, 0]); high = float(ci[-1, 1])
                return mu, low, high
            except Exception as e:
                print(f"ARIMA é¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨ç»éªŒèŒƒå›´: {e}")
                series = [sum(r["red_balls"]) for r in self.lottery_data]
                mu = np.mean(series)
                return float(mu), float(mu-25), float(mu+25)

    def _sample_combo_no_replace(self, prob_red, k=6):
        """Sample k distinct red numbers without replacement according to prob_red."""
        prob = prob_red.copy().astype(np.float64)
        prob = prob / prob.sum()
        chosen = []
        available = np.arange(1, 34)
        for _ in range(k):
            idxs = np.array([i-1 for i in available])
            p = prob[idxs]; p = p / p.sum()
            pick = np.random.choice(len(available), p=p)
            val = int(available[pick])
            chosen.append(val)
            available = np.array([x for x in available if x != val])
        return sorted(chosen)

    def _monte_carlo_candidates(self, p_red, p_blue, n=2000, sum_mu=None, sum_low=None, sum_high=None, recent_hot_blues=None):
            """
            Monte Carlo guided by probabilities & optional sum constraints.
            Returns list of (reds, blue, score, entropy_bits).
            """
            candidates = {}
            for _ in range(n):
                reds = self._sample_combo_no_replace(p_red, k=6)
                s = sum(reds)
                if sum_low is not None and sum_high is not None and not (sum_low <= s <= sum_high):
                    continue
                # é€‰ä¸­é›†çš„ç†µä¸è¯„åˆ†
                q = np.array([p_red[r-1] for r in reds], dtype=np.float64)
                q = q / q.sum()
                H = self.compute_entropy(q)
                mean_p = float(np.mean([p_red[r-1] for r in reds]))
                score = 0.7 * mean_p - 0.3 * (H / np.log2(6))

                # è“çƒï¼šè‡ªé€‚åº” top-k + çƒ­è“é›†åˆï¼Œä½†çƒ­è“æ€»ä½“æƒé‡â‰¤40%
                sharp = float(np.max(p_blue))
                k_adapt = int(np.clip(6 - round(4 * sharp / (np.max(p_blue) + 1e-12)), 2, 6))
                k_adapt = min(k_adapt, len(p_blue))
                top_idx = np.argsort(p_blue)[-k_adapt:]

                hot_set = set(recent_hot_blues or [])
                hot_idx = sorted({b-1 for b in hot_set if 1 <= b <= 16})
                merged = sorted(set(top_idx.tolist()) | set(hot_idx))
                base = p_blue[merged].astype(np.float64)
                base = base / (base.sum() + 1e-12)

                # æŒ‰ç»„åŠ æƒï¼šhot â‰¤ 0.4ï¼Œå…¶ä½™åˆ†ç»™éçƒ­è“
                if merged:
                    mask_hot = np.array([1 if i in hot_idx else 0 for i in merged], dtype=np.float64)
                    w_hot = min(0.40, float(mask_hot.sum()) / max(1.0, len(merged)))  # ä¸Šé™ 40%
                    w_cold = 1.0 - w_hot
                    if mask_hot.sum() > 0 and mask_hot.sum() < len(merged):
                        base_hot = base * mask_hot
                        base_cold = base * (1.0 - mask_hot)
                        # å½’ä¸€åŒ–åˆ°å„è‡ªæƒé‡
                        sh = base_hot.sum(); sc = base_cold.sum()
                        if sh > 0: base_hot = (base_hot / sh) * w_hot
                        if sc > 0: base_cold = (base_cold / sc) * w_cold
                        mix_probs = base_hot + base_cold
                    else:
                        mix_probs = base  # å…¨çƒ­æˆ–å…¨å†·æ—¶ç›´æ¥ç”¨ base
                else:
                    mix_probs = base
                mix_probs = mix_probs / (mix_probs.sum() + 1e-12)

                blue_idx = int(merged[np.random.choice(len(merged), p=mix_probs)]) + 1
                key = (tuple(reds), blue_idx)
                if key not in candidates or score > candidates[key][0]:
                    candidates[key] = (score, H)

            out = []
            for (reds, blue), (score, H) in candidates.items():
                out.append((list(reds), int(blue), float(score), float(H)))
            out.sort(key=lambda x: -x[2])
            return out
    
    # ------------------ end of ML helpers & models ------------------


    def analyze_patterns(self):
        """åˆ†æå·ç è§„å¾‹"""
        print("\n=== å·ç è§„å¾‹åˆ†æ ===")
        
        # å¥‡å¶åˆ†å¸ƒåˆ†æ
        odd_even_dist = defaultdict(int)
        sum_dist = defaultdict(int)
        span_dist = defaultdict(int)
        
        for record in self.lottery_data:
            red_balls = record['red_balls']
            
            # å¥‡å¶åˆ†æ
            odd_count = sum(1 for x in red_balls if x % 2 == 1)
            even_count = 6 - odd_count
            odd_even_dist[f"{odd_count}å¥‡{even_count}å¶"] += 1
            
            # å’Œå€¼åˆ†æ
            total_sum = sum(red_balls)
            sum_range = f"{(total_sum//10)*10}-{(total_sum//10)*10+9}"
            sum_dist[sum_range] += 1
            
            # è·¨åº¦åˆ†æ
            span = max(red_balls) - min(red_balls)
            span_range = f"{(span//5)*5}-{(span//5)*5+4}"
            span_dist[span_range] += 1
        
        print("\nå¥‡å¶åˆ†å¸ƒç»Ÿè®¡ï¼š")
        for pattern, count in sorted(odd_even_dist.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(self.lottery_data)) * 100
            print(f"{pattern}: {count} æ¬¡ ({percentage:.1f}%)")
        
        print("\nå’Œå€¼åˆ†å¸ƒç»Ÿè®¡ï¼š")
        for sum_range, count in sorted(sum_dist.items(), key=lambda x: int(x[0].split('-')[0])):
            percentage = (count / len(self.lottery_data)) * 100
            print(f"{sum_range}: {count} æ¬¡ ({percentage:.1f}%)")
        
        print("\nè·¨åº¦åˆ†å¸ƒç»Ÿè®¡ï¼š")
        for span_range, count in sorted(span_dist.items(), key=lambda x: int(x[0].split('-')[0])):
            percentage = (count / len(self.lottery_data)) * 100
            print(f"{span_range}: {count} æ¬¡ ({percentage:.1f}%)")
    
    def analyze_trends(self):
        """åˆ†æèµ°åŠ¿"""
        print("\n=== èµ°åŠ¿åˆ†æ ===")
        
        if len(self.lottery_data) < 10:
            print("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œèµ°åŠ¿åˆ†æ")
            return
        
        # æœ€è¿‘10æœŸçš„å·ç ï¼ˆæŒ‰æ—¥æœŸå€’åºï¼‰
        data_sorted = sorted(self.lottery_data, key=lambda r: (r['date'], r['period']), reverse=True)
        recent_10 = data_sorted[:10]
        
        print("æœ€è¿‘10æœŸå¼€å¥–å·ç ï¼š")
        for record in recent_10:
            red_str = " ".join([f"{x:2d}" for x in record['red_balls']])
            print(f"{record['period']}: {red_str} + {record['blue_ball']:2d}")
        
        # å†·çƒ­å·åˆ†æ
        red_counter = Counter()
        blue_counter = Counter()
        
        for record in recent_10:
            for red in record['red_balls']:
                red_counter[red] += 1
            blue_counter[record['blue_ball']] += 1
        
        print(f"\næœ€è¿‘10æœŸçº¢çƒçƒ­å·ï¼ˆå‡ºç°2æ¬¡åŠä»¥ä¸Šï¼‰ï¼š")
        hot_reds = [num for num, count in red_counter.items() if count >= 2]
        if hot_reds:
            hot_reds.sort()
            print(" ".join([f"{x:2d}" for x in hot_reds]))
        else:
            print("æ— ")
        
        print(f"\næœ€è¿‘10æœŸè“çƒçƒ­å·ï¼ˆå‡ºç°2æ¬¡åŠä»¥ä¸Šï¼‰ï¼š")
        hot_blues = [num for num, count in blue_counter.items() if count >= 2]
        if hot_blues:
            hot_blues.sort()
            print(" ".join([f"{x:2d}" for x in hot_blues]))
        else:
            print("æ— ")
    
    def generate_recommendations(self, num_sets=5):
        """ä½¿ç”¨ LSTM + æ—¶é—´è¡°å‡é¢‘ç‡ + ARIMA çº¦æŸ + Monte Carlo çš„ä½ç†µæ¨è"""
        print(f"\n=== ç”Ÿæˆ {num_sets} ç»„æœºå™¨å­¦ä¹ å¢å¼ºæ¨è ===")
        if not self.lottery_data:
            print("æ— æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆæ¨è")
            return []

        # 1) fused probabilities (ML + time-decayed marginals)
        p_red, p_blue = self.predict_next_probabilities(blend_alpha="auto", decay_half_life=60)
        print("å…ˆéªŒ: ä¸‰å‘èåˆ(çŸ­çª—/å‘¨å‡ /å…¨å±€) + æ¸©åº¦(Tred=1.3, Tblue=1.5Â±)")
        self._last_pred_probs = (p_red, p_blue)

        # 2) ARIMA sum forecast -> range constraint
        mu, low, high = self._arima_sum_forecast(horizon=1)
        sum_low = max(60, int(low) - 5)
        sum_high = min(180, int(high) + 5)
        print(f"ARIMA é¢„æµ‹å’Œå€¼åŒºé—´: ç›®æ ‡â‰ˆ{mu:.1f}, å…è®¸èŒƒå›´ [{sum_low}, {sum_high}]")

        # 3) Monte Carlo candidates with entropy penalty
        raw_candidates = self._monte_carlo_candidates(
            p_red, p_blue, n=2500, sum_mu=mu, sum_low=sum_low, sum_high=sum_high,
            recent_hot_blues=self._recent_hot_blues(window=10, min_count=2)
        )
        if not raw_candidates:
            print("å€™é€‰ä¸ºç©ºï¼Œå›é€€åˆ°æ— å’Œå€¼çº¦æŸçš„é‡‡æ ·ã€‚")
        # å›é€€æ—¶ï¼š
            raw_candidates = self._monte_carlo_candidates(
                p_red, p_blue, n=2500,
                recent_hot_blues=self._recent_hot_blues(window=10, min_count=2)
            )

        # 4) take top-K unique
        recommendations = []
        used_red_sets = set()
        for reds, blue, score, H in raw_candidates:
            key = tuple(reds)
            if key in used_red_sets:
                continue
            odd_count = sum(1 for x in reds if x % 2)
            even_count = 6 - odd_count
            span = max(reds) - min(reds)
            total_sum = sum(reds)
            conf = float(np.mean([p_red[r-1] for r in reds]) * p_blue[blue-1])
            recommendations.append({
                'red_balls': reds,
                'blue_ball': blue,
                'description': 'LSTM+ARIMA+MonteCarlo ä½ç†µç»„åˆ',
                'strategy': 'MLä½ç†µ',
                'odd_even': f"{odd_count}å¥‡{even_count}å¶",
                'sum': total_sum,
                'span': span,
                'entropy_bits': round(H, 4),
                'confidence': round(conf, 6),
            })
            used_red_sets.add(key)
            if len(recommendations) >= num_sets:
                break

        print("\næœºå™¨å­¦ä¹ å¢å¼ºæ¨èï¼š")
        for i, rec in enumerate(recommendations, 1):
            red_str = " ".join([f"{x:2d}" for x in rec['red_balls']])
            print(f"æ¨è {i}: {red_str} + {rec['blue_ball']:2d} | ç†µ:{rec['entropy_bits']:.3f}bits | ç½®ä¿¡åº¦:{rec['confidence']:.6f} | å’Œå€¼:{rec['sum']} | è·¨åº¦:{rec['span']} | {rec['odd_even']}")

        return recommendations

    def evaluate_latest_draw(self, recommendations):
        """æŠ¥å‘Šæœ€æ–°ä¸€æœŸä¸æ¨è/æ¦‚ç‡çš„å¯¹æ¯”"""
        if not self.lottery_data:
            print("æ— æ•°æ®ï¼Œæ— æ³•è¯„ä¼°å½“æœŸå‘½ä¸­æƒ…å†µ")
            return
        latest = self._sorted_data(descending=True)[0]
        reds_true = set(latest['red_balls'])
        blue_true = latest['blue_ball']

        p_red, p_blue = getattr(self, '_last_pred_probs', (None, None))
        if p_red is not None and p_blue is not None:
            red_mass = float(sum(p_red[r-1] for r in reds_true))
            blue_rank = int((16 - np.argsort(np.argsort(p_blue))[blue_true-1]))  # 1=æœ€é«˜
            blue_top3 = blue_rank <= 3
        else:
            red_mass, blue_rank, blue_top3 = float('nan'), -1, False

        best_overlap = 0
        blue_hit = False
        for rec in recommendations:
            ov = len(reds_true.intersection(rec['red_balls']))
            best_overlap = max(best_overlap, ov)
            if rec['blue_ball'] == blue_true:
                blue_hit = True

        print("\n=== å½“æœŸå›æµ‹ï¼ˆæœ€æ–°æœŸï¼‰ ===")
        print(f"æœŸå·: {latest['period']} æ—¥æœŸ: {latest['date']} å¼€å¥–: {sorted(list(reds_true))} + {blue_true:02d}")
        print(f"æ¨èç»„åˆæœ€ä½³çº¢çƒé‡åˆæ•°: {best_overlap} / 6 | æ˜¯å¦å‘½ä¸­è“çƒ: {'æ˜¯' if blue_hit else 'å¦'}")
        if p_red is not None:
            print(f"çº¢çƒæ¦‚ç‡è´¨é‡(çœŸå€¼æ€»å’Œ): {red_mass:.4f} | è“çƒæ¦‚ç‡åæ¬¡: Top-{blue_rank}{' (â‰¤3)' if blue_top3 else ''}")
        if blue_hit and best_overlap == 6: tier = 'ä¸€ç­‰å¥–(ç†è®º)'
        elif best_overlap == 6:           tier = 'äºŒç­‰å¥–(ç†è®º)'
        elif best_overlap == 5 and blue_hit: tier = 'ä¸‰ç­‰å¥–(ç†è®º)'
        elif (best_overlap == 5) or (best_overlap == 4 and blue_hit): tier = 'å››ç­‰å¥–(ç†è®º)'
        elif (best_overlap == 4) or (best_overlap == 3 and blue_hit): tier = 'äº”ç­‰å¥–(ç†è®º)'
        elif (best_overlap == 2 and blue_hit): tier = 'å…­ç­‰å¥–(ç†è®º)'
        else: tier = 'æœªä¸­å¥–(ç†è®º)'
        print(f"æŒ‰æœ€ä½³é‡åˆä¼°è®¡å¥–çº§: {tier}")    
    def _select_with_odd_even_balance(self, pool, count, existing_reds):
        """åœ¨é€‰æ‹©æ—¶è€ƒè™‘å¥‡å¶å¹³è¡¡"""
        if count <= 0:
            return []
            
        existing_odd = sum(1 for x in existing_reds if x % 2 == 1)
        existing_even = len(existing_reds) - existing_odd
        
        # ç›®æ ‡ï¼š6ä¸ªçƒä¸­3-4ä¸ªå¥‡æ•°æ¯”è¾ƒå¹³è¡¡
        target_total_odd = 3 if len(existing_reds) + count <= 6 else 4
        needed_odd = max(0, target_total_odd - existing_odd)
        needed_even = count - needed_odd
        
        odd_pool = [x for x in pool if x % 2 == 1]
        even_pool = [x for x in pool if x % 2 == 0]
        
        selected = []
        
        # é€‰æ‹©å¥‡æ•°
        if needed_odd > 0 and odd_pool:
            actual_odd = min(needed_odd, len(odd_pool))
            selected.extend(random.sample(odd_pool, actual_odd))
        
        # é€‰æ‹©å¶æ•°
        if needed_even > 0 and even_pool:
            actual_even = min(needed_even, len(even_pool))
            selected.extend(random.sample(even_pool, actual_even))
        
        # å¦‚æœè¿˜ä¸å¤Ÿï¼Œä»å‰©ä½™çš„çƒä¸­è¡¥å……
        while len(selected) < count and len(selected) < len(pool):
            remaining = [x for x in pool if x not in selected]
            if remaining:
                selected.append(random.choice(remaining))
            else:
                break
        
        return selected[:count]
    
    def visualize_frequency(self, save_plots=True):
        """å¯è§†åŒ–é¢‘ç‡åˆ†æ"""
        if not self.lottery_data:
            print("æ— æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨")
            return
        
        # ç»Ÿè®¡é¢‘ç‡
        red_counter = Counter()
        blue_counter = Counter()
        
        for record in self.lottery_data:
            for red in record['red_balls']:
                red_counter[red] += 1
            blue_counter[record['blue_ball']] += 1
        
        # åˆ›å»ºå›¾è¡¨
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))
        
        # çº¢çƒé¢‘ç‡å›¾
        red_nums = list(range(1, 34))
        red_freqs = [red_counter.get(num, 0) for num in red_nums]
        
        bars1 = ax1.bar(red_nums, red_freqs, color='red', alpha=0.7)
        ax1.set_title('çº¢çƒå‡ºç°é¢‘ç‡åˆ†å¸ƒ', fontsize=16, fontweight='bold')
        ax1.set_xlabel('çº¢çƒå·ç ', fontsize=12)
        ax1.set_ylabel('å‡ºç°æ¬¡æ•°', fontsize=12)
        ax1.set_xticks(red_nums)
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, freq in zip(bars1, red_freqs):
            if freq > 0:
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                        str(freq), ha='center', va='bottom', fontsize=8)
        
        # è“çƒé¢‘ç‡å›¾
        blue_nums = list(range(1, 17))
        blue_freqs = [blue_counter.get(num, 0) for num in blue_nums]
        
        bars2 = ax2.bar(blue_nums, blue_freqs, color='blue', alpha=0.7)
        ax2.set_title('è“çƒå‡ºç°é¢‘ç‡åˆ†å¸ƒ', fontsize=16, fontweight='bold')
        ax2.set_xlabel('è“çƒå·ç ', fontsize=12)
        ax2.set_ylabel('å‡ºç°æ¬¡æ•°', fontsize=12)
        ax2.set_xticks(blue_nums)
        ax2.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, freq in zip(bars2, blue_freqs):
            if freq > 0:
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                        str(freq), ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        
        if save_plots:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs('pics', exist_ok=True)
            plt.savefig('pics/lottery_frequency_analysis.png', dpi=300, bbox_inches='tight')
            print("é¢‘ç‡åˆ†æå›¾è¡¨å·²ä¿å­˜ä¸º pics/lottery_frequency_analysis.png")
    
    def get_lottery_rules(self):
        """è·å–åŒè‰²çƒæ¸¸æˆè§„åˆ™"""
        rules = """
        === åŒè‰²çƒæ¸¸æˆè§„åˆ™ ===
        
        1. å·ç èŒƒå›´ï¼š
           - çº¢çƒï¼š01-33ï¼Œé€‰æ‹©6ä¸ªå·ç 
           - è“çƒï¼š01-16ï¼Œé€‰æ‹©1ä¸ªå·ç 
        
        2. ä¸­å¥–ç­‰çº§ï¼š
           ä¸€ç­‰å¥–ï¼š6ä¸ªçº¢çƒ + 1ä¸ªè“çƒï¼ˆæµ®åŠ¨å¥–é‡‘ï¼Œ500ä¸‡å…ƒèµ·ï¼‰
           äºŒç­‰å¥–ï¼š6ä¸ªçº¢çƒï¼ˆæµ®åŠ¨å¥–é‡‘ï¼‰
           ä¸‰ç­‰å¥–ï¼š5ä¸ªçº¢çƒ + 1ä¸ªè“çƒï¼ˆå›ºå®š3000å…ƒï¼‰
           å››ç­‰å¥–ï¼š5ä¸ªçº¢çƒ æˆ– 4ä¸ªçº¢çƒ + 1ä¸ªè“çƒï¼ˆå›ºå®š200å…ƒï¼‰
           äº”ç­‰å¥–ï¼š4ä¸ªçº¢çƒ æˆ– 3ä¸ªçº¢çƒ + 1ä¸ªè“çƒï¼ˆå›ºå®š10å…ƒï¼‰
           å…­ç­‰å¥–ï¼š2ä¸ªçº¢çƒ + 1ä¸ªè“çƒ æˆ– 1ä¸ªçº¢çƒ + 1ä¸ªè“çƒ æˆ– 1ä¸ªè“çƒï¼ˆå›ºå®š5å…ƒï¼‰
        
        3. å¼€å¥–æ—¶é—´ï¼šæ¯å‘¨äºŒã€å››ã€æ—¥æ™š21:15
        
        4. æŠ•æ³¨æ–¹å¼ï¼š
           - å•å¼æŠ•æ³¨ï¼šæ‰‹åŠ¨é€‰æ‹©å·ç 
           - å¤å¼æŠ•æ³¨ï¼šé€‰æ‹©7ä¸ªä»¥ä¸Šçº¢çƒè¿›è¡Œç»„åˆ
           - æœºé€‰æŠ•æ³¨ï¼šç³»ç»Ÿéšæœºé€‰æ‹©å·ç 
        
        5. ä¸­å¥–æ¦‚ç‡ï¼š
           ä¸€ç­‰å¥–ï¼š1/17,721,088
           äºŒç­‰å¥–ï¼š1/1,107,568
           ä¸‰ç­‰å¥–ï¼š1/72,107
           
        æ³¨æ„ï¼šå½©ç¥¨æŠ•æ³¨æœ‰é£é™©ï¼Œè¯·ç†æ€§è´­å½©ï¼Œé‡åŠ›è€Œè¡Œï¼
        """
        print(rules)
    
    def generate_analysis_report(self, filename="reports/double_color_ball_analysis_report.md"):
        """ç”Ÿæˆå®Œæ•´çš„åˆ†ææŠ¥å‘Šæ–‡ä»¶"""
        print(f"æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š: {filename}")
        
        if not self.lottery_data:
            print("æ— æ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
            return
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        # æ‰§è¡Œæ‰€æœ‰åˆ†æ
        red_counter, blue_counter = self._get_frequency_analysis()
        patterns_data = self._get_patterns_analysis()
        trends_data = self._get_trends_analysis()
        recommendations = self.generate_recommendations(num_sets=8)
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹ UTC+8æ—¶åŒº
        current_time = (datetime.now() + timedelta(hours=8)).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
        
        report_content = f"""# ğŸ¯ åŒè‰²çƒæ•°æ®åˆ†ææŠ¥å‘Š

## ğŸ“Š æŠ¥å‘Šä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {current_time} (UTC+8)
- **æ•°æ®æœŸæ•°**: å…± {len(self.lottery_data)} æœŸ
- **ä¸‹ä¸€æœŸå¼€å¥–æ—¥(æŒ‰å‘¨)**: {['å‘¨ä¸€','å‘¨äºŒ','å‘¨ä¸‰','å‘¨å››','å‘¨äº”','å‘¨å…­','å‘¨æ—¥'][self._next_draw_weekday()]}
- **æœ€æ–°æœŸå·**: {self._sorted_data(descending=True)[0]['period'] if self.lottery_data else 'N/A'}
- **æ•°æ®æ¥æº**: ä¸­å›½ç¦åˆ©å½©ç¥¨å®˜æ–¹API

## âš ï¸ é‡è¦å…è´£å£°æ˜
**æœ¬åˆ†ææŠ¥å‘Šä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ï¼Œå½©ç¥¨å¼€å¥–å®Œå…¨éšæœºï¼Œå†å²æ•°æ®æ— æ³•é¢„æµ‹æœªæ¥ç»“æœã€‚è¯·ç†æ€§è´­å½©ï¼Œé‡åŠ›è€Œè¡Œï¼**

---

## ğŸ“ˆ æœ€æ–°å¼€å¥–ä¿¡æ¯

"""
        
        # æ·»åŠ æœ€è¿‘5æœŸå¼€å¥–ä¿¡æ¯
        if len(self.lottery_data) >= 5:
            report_content += "### æœ€è¿‘5æœŸå¼€å¥–å·ç \n\n"
            latest5 = self._sorted_data(descending=True)[:5]
            for i, record in enumerate(latest5):
                red_str = " ".join([f"{x:02d}" for x in record['red_balls']])
                report_content += f"**{record['period']}æœŸ** ({record['date']}): {red_str} + **{record['blue_ball']:02d}**\n\n"
        
        # æ·»åŠ å·ç é¢‘ç‡åˆ†æ
        report_content += """---

## ğŸ”¥ å·ç é¢‘ç‡åˆ†æ

### çº¢çƒå‡ºç°é¢‘ç‡æ’è¡Œæ¦œï¼ˆå‰15åï¼‰

| æ’å | å·ç  | å‡ºç°æ¬¡æ•° | å‡ºç°é¢‘ç‡ |
|------|------|----------|----------|
"""
        
        red_freq = sorted(red_counter.items(), key=lambda x: x[1], reverse=True)
        for i, (num, count) in enumerate(red_freq[:15], 1):
            percentage = (count / len(self.lottery_data)) * 100
            report_content += f"| {i:02d} | **{num:02d}** | {count} | {percentage:.1f}% |\n"
        
        report_content += """
### è“çƒå‡ºç°é¢‘ç‡æ’è¡Œæ¦œï¼ˆå‰10åï¼‰

| æ’å | å·ç  | å‡ºç°æ¬¡æ•° | å‡ºç°é¢‘ç‡ |
|------|------|----------|----------|
"""
        
        blue_freq = sorted(blue_counter.items(), key=lambda x: x[1], reverse=True)
        for i, (num, count) in enumerate(blue_freq[:10], 1):
            percentage = (count / len(self.lottery_data)) * 100
            report_content += f"| {i:02d} | **{num:02d}** | {count} | {percentage:.1f}% |\n"
        
        # æ·»åŠ è§„å¾‹åˆ†æ
        report_content += f"""
---

## ğŸ“Š å·ç è§„å¾‹åˆ†æ

### å¥‡å¶åˆ†å¸ƒç»Ÿè®¡

{patterns_data['odd_even']}

### å’Œå€¼åˆ†å¸ƒç»Ÿè®¡

{patterns_data['sum_dist']}

### è·¨åº¦åˆ†å¸ƒç»Ÿè®¡

{patterns_data['span_dist']}

---

## ğŸ“‰ èµ°åŠ¿åˆ†æ

### æœ€è¿‘10æœŸå¼€å¥–è®°å½•

{trends_data['recent_draws']}

### çƒ­å·åˆ†æ

**æœ€è¿‘10æœŸçº¢çƒçƒ­å·ï¼ˆå‡ºç°2æ¬¡åŠä»¥ä¸Šï¼‰**: {trends_data['hot_reds']}

**æœ€è¿‘10æœŸè“çƒçƒ­å·ï¼ˆå‡ºç°2æ¬¡åŠä»¥ä¸Šï¼‰**: {trends_data['hot_blues']}

---

## ğŸ¯ æ™ºèƒ½æ¨èå·ç 

**âš ï¸ ä»¥ä¸‹æ¨èå·ç ä»…åŸºäºå†å²ç»Ÿè®¡åˆ†æï¼Œä¸ä¿è¯ä¸­å¥–ï¼Œè¯·ç†æ€§å‚è€ƒï¼**

"""
        
        for i, rec in enumerate(recommendations, 1):
            red_str = " ".join([f"{x:02d}" for x in rec['red_balls']])
            report_content += f"**æ¨èç»„åˆ {i}** ({rec.get('strategy','MLä½ç†µ')}): {red_str} + **{rec['blue_ball']:02d}**\n"
            report_content += f"- ç‰¹å¾: {rec['odd_even']} | å’Œå€¼:{rec['sum']} | è·¨åº¦:{rec['span']}\n"
            if 'entropy_bits' in rec:
                report_content += f"- ä¿¡æ¯ç†µ: {rec['entropy_bits']} bits\n"
            if 'confidence' in rec:
                report_content += f"- ç½®ä¿¡åº¦(ç›¸å¯¹): {rec['confidence']}\n"
            report_content += f"- è¯´æ˜: {rec.get('description','LSTM+ARIMA+MonteCarlo ä½ç†µç»„åˆ')}\n\n"
        
        # æ·»åŠ ä½¿ç”¨è¯´æ˜å’Œæé†’
        report_content += f"""---

## ğŸ“‹ ä½¿ç”¨è¯´æ˜

### æ•°æ®æ›´æ–°é¢‘ç‡
- æœ¬æŠ¥å‘Šæ¯å¤©è‡ªåŠ¨æ›´æ–°ä¸€æ¬¡
- æ•°æ®æ¥æºäºä¸­å›½ç¦åˆ©å½©ç¥¨å®˜æ–¹API
- æ›´æ–°æ—¶é—´ï¼šæ¯å¤©æ™šä¸Š23:00

### åˆ†ææ–¹æ³•è¯´æ˜
1. **é¢‘ç‡åˆ†æ**: ç»Ÿè®¡æ¯ä¸ªå·ç åœ¨å†å²å¼€å¥–ä¸­çš„å‡ºç°æ¬¡æ•°
2. **è§„å¾‹åˆ†æ**: åˆ†æå¥‡å¶åˆ†å¸ƒã€å’Œå€¼åˆ†å¸ƒã€è·¨åº¦åˆ†å¸ƒç­‰è§„å¾‹
3. **èµ°åŠ¿åˆ†æ**: è§‚å¯Ÿæœ€è¿‘æœŸæ•°çš„å·ç èµ°åŠ¿å’Œçƒ­å·å˜åŒ–
4. **æ™ºèƒ½æ¨è**: åŸºäºç»Ÿè®¡æ¦‚ç‡å’Œéšæœºæ€§çš„æƒé‡ç®—æ³•ç”Ÿæˆæ¨èå·ç 

### é‡è¦æé†’

> ğŸ² **å½©ç¥¨æœ¬è´¨**: å½©ç¥¨å¼€å¥–å…·æœ‰å®Œå…¨çš„éšæœºæ€§å’Œå¶ç„¶æ€§
> 
> ğŸ“Š **æ•°æ®å±€é™**: å†å²æ•°æ®æ— æ³•é¢„æµ‹æœªæ¥å¼€å¥–ç»“æœ
> 
> ğŸ¯ **å‚è€ƒä»·å€¼**: æœ¬åˆ†æä»…ä¾›ç»Ÿè®¡å­¦ä¹ å’Œå¨±ä¹å‚è€ƒ
> 
> ğŸ’° **ç†æ€§è´­å½©**: è¯·æ ¹æ®ä¸ªäººç»æµèƒ½åŠ›é€‚åº¦è´­ä¹°
> 
> âš–ï¸ **æ³•å¾‹æé†’**: æœªæ»¡18å‘¨å²ç¦æ­¢è´­ä¹°å½©ç¥¨
> 
> ğŸ  **å®¶åº­å’Œç¦**: åˆ‡å‹¿å› è´­å½©å½±å“å®¶åº­ç”Ÿæ´»

---

## ğŸ“ å¸®åŠ©ä¿¡æ¯

å¦‚æœæ‚¨æˆ–èº«è¾¹çš„äººå‡ºç°ä»¥ä¸‹æƒ…å†µï¼Œè¯·åŠæ—¶å¯»æ±‚å¸®åŠ©ï¼š
- æ— æ³•æ§åˆ¶è´­å½©è¡Œä¸º
- ä¸ºäº†è´­å½©å€Ÿé’±æˆ–å˜å–è´¢äº§
- å› è´­å½©å½±å“å·¥ä½œã€å­¦ä¹ æˆ–å®¶åº­å…³ç³»
- å‡ºç°ç„¦è™‘ã€æŠ‘éƒç­‰å¿ƒç†é—®é¢˜

**å…¨å›½æˆ’èµŒå¸®åŠ©çƒ­çº¿**: 400-161-9995

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {current_time} (UTC+8)*  
*æ•°æ®æ¥æº: ä¸­å›½ç¦åˆ©å½©ç¥¨å®˜æ–¹ç½‘ç«™*  
*ä»…ä¾›å­¦ä¹ ç ”ç©¶ä½¿ç”¨ï¼Œè¯·ç†æ€§è´­å½©*
"""
        
        # ä¿å­˜æŠ¥å‘Šæ–‡ä»¶
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            print(f"ä¿å­˜åˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
    
    def _get_frequency_analysis(self):
        """å†…éƒ¨æ–¹æ³•ï¼šè·å–é¢‘ç‡åˆ†ææ•°æ®"""
        red_counter = Counter()
        blue_counter = Counter()
        
        for record in self.lottery_data:
            for red in record['red_balls']:
                red_counter[red] += 1
            blue_counter[record['blue_ball']] += 1
        
        return red_counter, blue_counter
    
    def _get_patterns_analysis(self):
        """å†…éƒ¨æ–¹æ³•ï¼šè·å–è§„å¾‹åˆ†ææ•°æ®"""
        odd_even_dist = defaultdict(int)
        sum_dist = defaultdict(int)
        span_dist = defaultdict(int)
        
        for record in self.lottery_data:
            red_balls = record['red_balls']
            
            # å¥‡å¶åˆ†æ
            odd_count = sum(1 for x in red_balls if x % 2 == 1)
            even_count = 6 - odd_count
            odd_even_dist[f"{odd_count}å¥‡{even_count}å¶"] += 1
            
            # å’Œå€¼åˆ†æ
            total_sum = sum(red_balls)
            sum_range = f"{(total_sum//10)*10}-{(total_sum//10)*10+9}"
            sum_dist[sum_range] += 1
            
            # è·¨åº¦åˆ†æ
            span = max(red_balls) - min(red_balls)
            span_range = f"{(span//5)*5}-{(span//5)*5+4}"
            span_dist[span_range] += 1
        
        # æ ¼å¼åŒ–æ•°æ®
        odd_even_result = "| åˆ†å¸ƒç±»å‹ | å‡ºç°æ¬¡æ•° | å‡ºç°é¢‘ç‡ |\n|----------|----------|----------|\n"
        for pattern, count in sorted(odd_even_dist.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(self.lottery_data)) * 100
            odd_even_result += f"| {pattern} | {count} | {percentage:.1f}% |\n"
        
        sum_result = "| å’Œå€¼èŒƒå›´ | å‡ºç°æ¬¡æ•° | å‡ºç°é¢‘ç‡ |\n|----------|----------|----------|\n"
        for sum_range, count in sorted(sum_dist.items(), key=lambda x: int(x[0].split('-')[0])):
            percentage = (count / len(self.lottery_data)) * 100
            sum_result += f"| {sum_range} | {count} | {percentage:.1f}% |\n"
        
        span_result = "| è·¨åº¦èŒƒå›´ | å‡ºç°æ¬¡æ•° | å‡ºç°é¢‘ç‡ |\n|----------|----------|----------|\n"
        for span_range, count in sorted(span_dist.items(), key=lambda x: int(x[0].split('-')[0])):
            percentage = (count / len(self.lottery_data)) * 100
            span_result += f"| {span_range} | {count} | {percentage:.1f}% |\n"
        
        return {
            'odd_even': odd_even_result,
            'sum_dist': sum_result,
            'span_dist': span_result
        }
    
    def _get_trends_analysis(self):
        """å†…éƒ¨æ–¹æ³•ï¼šè·å–è¶‹åŠ¿åˆ†ææ•°æ®"""
        if len(self.lottery_data) < 10:
            return {
                'recent_draws': 'æ•°æ®ä¸è¶³',
                'hot_reds': 'æ— ',
                'hot_blues': 'æ— '
            }
        
        data_sorted = self._sorted_data(descending=True)
        recent_10 = data_sorted[:10]   
             
        # æ ¼å¼åŒ–æœ€è¿‘10æœŸ
        recent_draws = "| æœŸå· | å¼€å¥–æ—¥æœŸ | çº¢çƒå·ç  | è“çƒ |\n|------|----------|----------|------|\n"
        for record in recent_10:
            red_str = " ".join([f"{x:02d}" for x in record['red_balls']])
            recent_draws += f"| {record['period']} | {record['date']} | {red_str} | **{record['blue_ball']:02d}** |\n"
        
        # å†·çƒ­å·åˆ†æ
        red_counter = Counter()
        blue_counter = Counter()
        
        for record in recent_10:
            for red in record['red_balls']:
                red_counter[red] += 1
            blue_counter[record['blue_ball']] += 1
        
        hot_reds = [num for num, count in red_counter.items() if count >= 2]
        hot_blues = [num for num, count in blue_counter.items() if count >= 2]
        
        hot_reds_str = " ".join([f"{x:02d}" for x in sorted(hot_reds)]) if hot_reds else "æ— "
        hot_blues_str = " ".join([f"{x:02d}" for x in sorted(hot_blues)]) if hot_blues else "æ— "
        
        return {
            'recent_draws': recent_draws,
            'hot_reds': hot_reds_str,
            'hot_blues': hot_blues_str
        }
    
    def generate_aggregated_data_hjson(self, filename="data/lottery_aggregated_data.hjson"):
        """ç”Ÿæˆèšåˆåˆ†ææ•°æ®çš„HJSONæ–‡ä»¶ï¼ŒåŒ…å«è¯¦ç»†æ³¨é‡Šä¾›AIç†è§£æ•°æ®ç”¨é€”"""
        print(f"æ­£åœ¨ç”Ÿæˆèšåˆæ•°æ®æ–‡ä»¶: {filename}")
        
        if not self.lottery_data:
            print("æ— æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆèšåˆæ•°æ®æ–‡ä»¶")
            return
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        # è·å–æ‰€æœ‰åˆ†ææ•°æ®
        red_counter, blue_counter = self._get_frequency_analysis()
        patterns_data = self._get_patterns_analysis_raw()
        trends_data = self._get_trends_analysis_raw()
        recommendations = self.generate_recommendations(num_sets=8)
        
        # ç”Ÿæˆæ—¶é—´ UTC+8
        current_time = (datetime.now() + timedelta(hours=8)).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
        
        # æ„å»ºèšåˆæ•°æ®ç»“æ„
        aggregated_data = {
            "// æ•°æ®æ–‡ä»¶è¯´æ˜": "åŒè‰²çƒå½©ç¥¨æ•°æ®èšåˆåˆ†æç»“æœï¼ŒåŒ…å«é¢‘ç‡ã€è§„å¾‹ã€èµ°åŠ¿ç­‰ç»Ÿè®¡æ•°æ®",
            "// æ–‡ä»¶ç”¨é€”": "ä¾›AIç³»ç»Ÿç†è§£æ•°æ®å«ä¹‰å¹¶ç”Ÿæˆç›¸åº”çš„æ•°æ®å¯è§†åŒ–å›¾è¡¨",
            "// æ›´æ–°é¢‘ç‡": "æ¯å¤©è‡ªåŠ¨æ›´æ–°ä¸€æ¬¡ï¼Œä¸å¼€å¥–æ•°æ®åŒæ­¥",
            
            "metadata": {
                "// å…ƒæ•°æ®è¯´æ˜": "åŒ…å«æ•°æ®çš„åŸºæœ¬ä¿¡æ¯å’Œç»Ÿè®¡æ¦‚å†µ",
                "lottery_type": "åŒè‰²çƒ",
                "lottery_type_en": "double_color_ball", 
                "game_rules": "çº¢çƒ1-33é€‰6ä¸ªï¼Œè“çƒ1-16é€‰1ä¸ª",
                "generated_time": current_time,
                "timezone": "UTC+8",
                "total_periods": len(self.lottery_data),
                "latest_period": self.lottery_data[0]['period'] if self.lottery_data else None,
                "latest_date": self.lottery_data[0]['date'] if self.lottery_data else None,
                "data_source": "ä¸­å›½ç¦åˆ©å½©ç¥¨å®˜æ–¹API"
            },
            
            "frequency_analysis": {
                "// é¢‘ç‡åˆ†æè¯´æ˜": "ç»Ÿè®¡æ¯ä¸ªå·ç åœ¨å†å²å¼€å¥–ä¸­çš„å‡ºç°æ¬¡æ•°å’Œé¢‘ç‡",
                "// å›¾è¡¨å»ºè®®": "é€‚åˆç»˜åˆ¶æŸ±çŠ¶å›¾ã€çƒ­åŠ›å›¾ã€é¢‘ç‡åˆ†å¸ƒå›¾",
                "// å¯è§†åŒ–ç”¨é€”": "å±•ç¤ºå·ç å†·çƒ­ç¨‹åº¦ï¼Œè¯†åˆ«é«˜é¢‘ä½é¢‘å·ç ",
                
                "red_balls": {
                    "// çº¢çƒé¢‘ç‡æ•°æ®": "çº¢çƒ1-33çš„å†å²å‡ºç°ç»Ÿè®¡",
                    "// æ•°æ®ç»“æ„": "number: å·ç , count: å‡ºç°æ¬¡æ•°, frequency: å‡ºç°é¢‘ç‡(%)",
                    "data": [
                        {
                            "number": num,
                            "count": red_counter.get(num, 0),
                            "frequency": round((red_counter.get(num, 0) / len(self.lottery_data)) * 100, 2)
                        } for num in range(1, 34)
                    ],
                    "// ç»Ÿè®¡æ‘˜è¦": "é¢‘ç‡åˆ†æçš„å…³é”®æŒ‡æ ‡",
                    "summary": {
                        "highest_freq_number": max(red_counter.items(), key=lambda x: x[1])[0] if red_counter else None,
                        "highest_freq_count": max(red_counter.items(), key=lambda x: x[1])[1] if red_counter else 0,
                        "lowest_freq_number": min(red_counter.items(), key=lambda x: x[1])[0] if red_counter else None,
                        "lowest_freq_count": min(red_counter.items(), key=lambda x: x[1])[1] if red_counter else 0,
                        "average_frequency": round(sum(red_counter.values()) / len(red_counter) if red_counter else 0, 2)
                    }
                },
                
                "blue_balls": {
                    "// è“çƒé¢‘ç‡æ•°æ®": "è“çƒ1-16çš„å†å²å‡ºç°ç»Ÿè®¡", 
                    "// æ•°æ®ç»“æ„": "number: å·ç , count: å‡ºç°æ¬¡æ•°, frequency: å‡ºç°é¢‘ç‡(%)",
                    "data": [
                        {
                            "number": num,
                            "count": blue_counter.get(num, 0),
                            "frequency": round((blue_counter.get(num, 0) / len(self.lottery_data)) * 100, 2)
                        } for num in range(1, 17)
                    ],
                    "// ç»Ÿè®¡æ‘˜è¦": "è“çƒé¢‘ç‡åˆ†æçš„å…³é”®æŒ‡æ ‡",
                    "summary": {
                        "highest_freq_number": max(blue_counter.items(), key=lambda x: x[1])[0] if blue_counter else None,
                        "highest_freq_count": max(blue_counter.items(), key=lambda x: x[1])[1] if blue_counter else 0,
                        "lowest_freq_number": min(blue_counter.items(), key=lambda x: x[1])[0] if blue_counter else None,
                        "lowest_freq_count": min(blue_counter.items(), key=lambda x: x[1])[1] if blue_counter else 0,
                        "average_frequency": round(sum(blue_counter.values()) / len(blue_counter) if blue_counter else 0, 2)
                    }
                }
            },
            
            "pattern_analysis": {
                "// è§„å¾‹åˆ†æè¯´æ˜": "åˆ†æå·ç çš„å¥‡å¶åˆ†å¸ƒã€å’Œå€¼åˆ†å¸ƒã€è·¨åº¦åˆ†å¸ƒç­‰è§„å¾‹",
                "// å›¾è¡¨å»ºè®®": "é€‚åˆç»˜åˆ¶é¥¼å›¾ã€å †å æŸ±çŠ¶å›¾ã€åˆ†å¸ƒç›´æ–¹å›¾",
                "// å¯è§†åŒ–ç”¨é€”": "å±•ç¤ºå·ç ç»„åˆçš„è§„å¾‹æ€§å’Œåˆ†å¸ƒç‰¹å¾",
                
                "odd_even_distribution": {
                    "// å¥‡å¶åˆ†å¸ƒ": "çº¢çƒ6ä¸ªå·ç ä¸­å¥‡æ•°å¶æ•°çš„åˆ†å¸ƒæƒ…å†µ",
                    "// å›¾è¡¨ç±»å‹": "é¥¼å›¾æˆ–æŸ±çŠ¶å›¾å±•ç¤ºå„ç§å¥‡å¶ç»„åˆçš„å‡ºç°é¢‘ç‡",
                    "data": patterns_data['odd_even_dist'],
                    "total_periods": len(self.lottery_data)
                },
                
                "sum_distribution": {
                    "// å’Œå€¼åˆ†å¸ƒ": "çº¢çƒ6ä¸ªå·ç æ€»å’Œçš„åˆ†å¸ƒåŒºé—´ç»Ÿè®¡",
                    "// å›¾è¡¨ç±»å‹": "ç›´æ–¹å›¾æˆ–æŠ˜çº¿å›¾å±•ç¤ºå’Œå€¼çš„åˆ†å¸ƒè§„å¾‹",
                    "// åˆ†ææ„ä¹‰": "å¸®åŠ©è¯†åˆ«å·ç ç»„åˆçš„å’Œå€¼è¶‹åŠ¿",
                    "data": patterns_data['sum_dist'],
                    "total_periods": len(self.lottery_data)
                },
                
                "span_distribution": {
                    "// è·¨åº¦åˆ†å¸ƒ": "çº¢çƒæœ€å¤§å·ç ä¸æœ€å°å·ç å·®å€¼çš„åˆ†å¸ƒç»Ÿè®¡",
                    "// å›¾è¡¨ç±»å‹": "æŸ±çŠ¶å›¾å±•ç¤ºä¸åŒè·¨åº¦èŒƒå›´çš„å‡ºç°é¢‘ç‡",
                    "// åˆ†ææ„ä¹‰": "åæ˜ å·ç é€‰æ‹©çš„åˆ†æ•£ç¨‹åº¦",
                    "data": patterns_data['span_dist'],
                    "total_periods": len(self.lottery_data)
                }
            },
            
            "trend_analysis": {
                "// èµ°åŠ¿åˆ†æè¯´æ˜": "åˆ†ææœ€è¿‘æœŸæ•°çš„å·ç èµ°åŠ¿å’Œçƒ­å·å˜åŒ–",
                "// å›¾è¡¨å»ºè®®": "é€‚åˆç»˜åˆ¶æ—¶é—´åºåˆ—å›¾ã€çƒ­åŠ›å›¾ã€è¶‹åŠ¿çº¿å›¾",
                "// å¯è§†åŒ–ç”¨é€”": "å±•ç¤ºçŸ­æœŸå†…å·ç çš„å†·çƒ­å˜åŒ–è¶‹åŠ¿",
                "// åˆ†æå‘¨æœŸ": "æœ€è¿‘10æœŸå¼€å¥–æ•°æ®",
                
                "recent_draws": trends_data['recent_draws'],
                "hot_numbers": {
                    "// çƒ­å·å®šä¹‰": "æœ€è¿‘10æœŸä¸­å‡ºç°2æ¬¡åŠä»¥ä¸Šçš„å·ç ",
                    "// å›¾è¡¨ç±»å‹": "æ ‡è®°å›¾æˆ–é«˜äº®æ˜¾ç¤ºçƒ­å·åœ¨èµ°åŠ¿å›¾ä¸­çš„ä½ç½®",
                    "red_hot_numbers": trends_data['hot_reds'],
                    "blue_hot_numbers": trends_data['hot_blues']
                }
            },
            
            "recommendations": {
                "// æ¨èå·ç è¯´æ˜": "åŸºäºå†å²ç»Ÿè®¡åˆ†æç”Ÿæˆçš„8ç§ç­–ç•¥æ¨èç»„åˆ",
                "// å›¾è¡¨å»ºè®®": "è¡¨æ ¼å±•ç¤ºæˆ–å¡ç‰‡å¼å¸ƒå±€å±•ç¤ºæ¨èç»„åˆ",
                "// é‡è¦æé†’": "ä»…ä¾›å‚è€ƒï¼Œå½©ç¥¨å¼€å¥–å®Œå…¨éšæœº",
                "// ç­–ç•¥è¯´æ˜": "åŒ…å«é«˜é¢‘ä¸»å¯¼ã€å‡è¡¡åˆ†å¸ƒã€å†·çƒ­ç»“åˆç­‰å¤šç§é€‰å·ç­–ç•¥",
                
                "strategies": [
                    {
                        "strategy_name": rec['strategy'],
                        "description": rec['description'],
                        "red_balls": rec['red_balls'],
                        "blue_ball": rec['blue_ball'],
                        "characteristics": {
                            "odd_even_ratio": rec['odd_even'],
                            "sum_value": rec['sum'],
                            "span_value": rec['span']
                        }
                    } for rec in recommendations
                ],
                
                "strategy_summary": {
                    "total_strategies": len(recommendations),
                    "strategy_types": [rec['strategy'] for rec in recommendations]
                }
            },
            
            "visualization_suggestions": {
                "// å¯è§†åŒ–å»ºè®®": "é’ˆå¯¹ä¸åŒæ•°æ®ç±»å‹çš„å›¾è¡¨ç»˜åˆ¶å»ºè®®",
                
                "frequency_charts": {
                    "chart_types": ["bar_chart", "heatmap", "bubble_chart"],
                    "description": "é¢‘ç‡æ•°æ®é€‚åˆç”¨æŸ±çŠ¶å›¾å±•ç¤ºæ’åï¼Œçƒ­åŠ›å›¾å±•ç¤ºåˆ†å¸ƒï¼Œæ°”æ³¡å›¾å±•ç¤ºé¢‘ç‡å¤§å°"
                },
                
                "pattern_charts": {
                    "chart_types": ["pie_chart", "stacked_bar", "histogram"],
                    "description": "è§„å¾‹æ•°æ®é€‚åˆç”¨é¥¼å›¾å±•ç¤ºæ¯”ä¾‹ï¼Œå †å æŸ±çŠ¶å›¾å±•ç¤ºåˆ†ç±»ï¼Œç›´æ–¹å›¾å±•ç¤ºåˆ†å¸ƒ"
                },
                
                "trend_charts": {
                    "chart_types": ["line_chart", "scatter_plot", "timeline"],
                    "description": "èµ°åŠ¿æ•°æ®é€‚åˆç”¨æŠ˜çº¿å›¾å±•ç¤ºå˜åŒ–ï¼Œæ•£ç‚¹å›¾å±•ç¤ºåˆ†å¸ƒï¼Œæ—¶é—´è½´å±•ç¤ºå†å²"
                },
                
                "recommendation_display": {
                    "display_types": ["table", "card_layout", "grid_view"],
                    "description": "æ¨èæ•°æ®é€‚åˆç”¨è¡¨æ ¼å±•ç¤ºè¯¦æƒ…ï¼Œå¡ç‰‡å¸ƒå±€å±•ç¤ºç­–ç•¥ï¼Œç½‘æ ¼è§†å›¾å±•ç¤ºç»„åˆ"
                }
            }
        }
        
        # ä¿å­˜HJSONæ–‡ä»¶
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                hjson.dump(aggregated_data, f, ensure_ascii=False, indent=2)
            print(f"èšåˆæ•°æ®æ–‡ä»¶å·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            print(f"ä¿å­˜èšåˆæ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
    
    def _get_patterns_analysis_raw(self):
        """å†…éƒ¨æ–¹æ³•ï¼šè·å–åŸå§‹è§„å¾‹åˆ†ææ•°æ®"""
        odd_even_dist = defaultdict(int)
        sum_dist = defaultdict(int)
        span_dist = defaultdict(int)
        
        for record in self.lottery_data:
            red_balls = record['red_balls']
            
            # å¥‡å¶åˆ†æ
            odd_count = sum(1 for x in red_balls if x % 2 == 1)
            even_count = 6 - odd_count
            odd_even_dist[f"{odd_count}å¥‡{even_count}å¶"] += 1
            
            # å’Œå€¼åˆ†æ
            total_sum = sum(red_balls)
            sum_range = f"{(total_sum//10)*10}-{(total_sum//10)*10+9}"
            sum_dist[sum_range] += 1
            
            # è·¨åº¦åˆ†æ
            span = max(red_balls) - min(red_balls)
            span_range = f"{(span//5)*5}-{(span//5)*5+4}"
            span_dist[span_range] += 1
        
        return {
            'odd_even_dist': dict(odd_even_dist),
            'sum_dist': dict(sum_dist),
            'span_dist': dict(span_dist)
        }
    
    def _get_trends_analysis_raw(self):
        """å†…éƒ¨æ–¹æ³•ï¼šè·å–åŸå§‹è¶‹åŠ¿åˆ†ææ•°æ®"""
        if len(self.lottery_data) < 10:
            return {
                'recent_draws': [],
                'hot_reds': [],
                'hot_blues': []
            }
        
        recent_10 = self.lottery_data[:10]
        
        # æœ€è¿‘10æœŸæ•°æ®
        recent_draws = []
        for record in recent_10:
            recent_draws.append({
                'period': record['period'],
                'date': record['date'],
                'red_balls': record['red_balls'],
                'blue_ball': record['blue_ball']
            })
        
        # å†·çƒ­å·åˆ†æ
        red_counter = Counter()
        blue_counter = Counter()
        
        for record in recent_10:
            for red in record['red_balls']:
                red_counter[red] += 1
            blue_counter[record['blue_ball']] += 1
        
        hot_reds = [num for num, count in red_counter.items() if count >= 2]
        hot_blues = [num for num, count in blue_counter.items() if count >= 2]
        
        return {
            'recent_draws': recent_draws,
            'hot_reds': sorted(hot_reds),
            'hot_blues': sorted(hot_blues)
        }
    
    def update_readme_recommendations(self, readme_path="reports/double_color_balls_profits.md", timestamp=None):
        """æ›´æ–°/æ›¿æ¢ README.md ä¸­çš„æ¨èå·ç åŒºå—ï¼ˆæ— é‡å¤ã€æ— ç¼©è¿›ä»£ç å—ï¼‰ã€‚
        - ä½¿ç”¨é”šç‚¹ `<!-- BEGIN:recommendations -->` ä¸ `<!-- END:recommendations -->` åŒ…è£¹å†…å®¹ï¼›
        - è‹¥é”šç‚¹å­˜åœ¨åˆ™åŸåœ°æ›¿æ¢ï¼›å¦åˆ™åœ¨ç¬¬ä¸€ä¸ª H1 æ ‡é¢˜åæ’å…¥ï¼›è‹¥æ‰¾ä¸åˆ° H1ï¼Œåˆ™è¿½åŠ åˆ°æœ«å°¾ï¼›
        - ç”Ÿæˆçš„ Markdown ä¸å¸¦å¤šä½™å‰å¯¼ç©ºæ ¼ï¼Œé¿å…è¢«æ¸²æŸ“ä¸ºä»£ç å—ã€‚
        """
        print(f"æ­£åœ¨æ›´æ–°README.mdä¸­çš„åŒè‰²çƒæ¨èå·ç ...")
        if not self.lottery_data:
            print("æ— æ•°æ®ï¼Œæ— æ³•æ›´æ–°READMEæ¨èå·ç ")
            return

        try:
            # ç”Ÿæˆæ¨èå·ç ï¼ˆé¿å…è¿‡å¤š I/O é‡å¤ï¼Œé»˜è®¤ 5 ç»„ï¼‰
            recommendations = self.generate_recommendations(num_sets=5)

            # è¯»å–æˆ–åˆå§‹åŒ– README å†…å®¹
            if not os.path.exists(readme_path):
                print("â„¹ï¸  README ä¸å­˜åœ¨ï¼šå°†åˆ›å»ºæœ€å° README ä¸é”šç‚¹åŒºå—ã€‚")
                content = "# ğŸ¯ åŒè‰²çƒå¼€å¥–æ•°æ®åˆ†æç³»ç»Ÿ\n\n> æœ¬ä»“åº“ä¸ºå†å²æ•°æ®åˆ†æä¸å¯è§†åŒ–ï¼Œä»…ä¾›å­¦ä¹ ç ”ç©¶ä½¿ç”¨ã€‚\n\n"
            else:
                with open(readme_path, 'r', encoding='utf-8') as f:
                    content = f.read()

            # æ—¶é—´æˆ³ï¼ˆUTC+8ï¼‰
            current_time = timestamp if timestamp else (datetime.now() + timedelta(hours=8)).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')

            # ç»„è£…æ¨èåŒºå—ï¼ˆä¸¥æ ¼é¿å…è¡Œé¦–ç¼©è¿›ï¼‰
            header_lines = [
                "<!-- BEGIN:recommendations -->",
                "## ğŸ¯ ä»Šæ—¥æ¨èå·ç ",
                "",
                "**âš ï¸ ä»¥ä¸‹æ¨èå·ç åŸºäºå†å²ç»Ÿè®¡åˆ†æï¼Œä»…ä¾›å‚è€ƒï¼Œä¸ä¿è¯ä¸­å¥–ï¼**",
                "",
                f"### åŒè‰²çƒæ¨è (æ›´æ–°æ—¶é—´: {current_time})",
                "",
            ]

            rec_lines = []
            for i, rec in enumerate(recommendations, 1):
                red_str = " ".join([f"{x:02d}" for x in rec['red_balls']])
                rec_lines.append(f"**æ¨è {i}** ({rec.get('strategy','MLä½ç†µ')}): `{red_str}` + `{rec['blue_ball']:02d}`  ")
                rec_lines.append(f"*{rec.get('description','LSTM+ARIMA+MonteCarlo ä½ç†µç»„åˆ')} | {rec['odd_even']} | å’Œå€¼:{rec['sum']} | è·¨åº¦:{rec['span']}*")
                rec_lines.append("")

            footer_lines = ["<!-- END:recommendations -->", ""]
            block = "\n".join(header_lines + rec_lines + footer_lines)

            # ç”¨é”šç‚¹æ›¿æ¢æˆ–æ’å…¥
            begin_tag = "<!-- BEGIN:recommendations -->"
            end_tag = "<!-- END:recommendations -->"

            if begin_tag in content and end_tag in content:
                # ç›´æ¥æ›¿æ¢é”šç‚¹ä¹‹é—´çš„å†…å®¹
                new_content = re.sub(
                    begin_tag + r"[\s\S]*?" + end_tag,
                    block,
                    content,
                    flags=re.MULTILINE
                )
                action = "æ›¿æ¢"
            else:
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ª H1 åæ’å…¥ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™æœ«å°¾è¿½åŠ ï¼‰
                lines = content.splitlines()
                insert_pos = -1
                for idx, line in enumerate(lines):
                    if line.startswith('# '):
                        insert_pos = idx + 1
                        break
                if insert_pos == -1:
                    # æœ«å°¾è¿½åŠ 
                    if content and not content.endswith('\n'):
                        content += '\n'
                    new_content = content + block
                    action = "è¿½åŠ "
                else:
                    # åœ¨ H1 åæ’å…¥ä¸€ä¸ªç©ºè¡Œ + åŒºå—
                    prefix = lines[:insert_pos]
                    suffix = lines[insert_pos:]
                    if len(prefix) == 0 or (prefix and prefix[-1].strip() != ""):
                        prefix.append("")
                    new_lines = prefix + [block] + [""] + suffix
                    new_content = "\n".join(new_lines)
                    action = "æ’å…¥"

            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(new_content)

            print(f"README.mdä¸­çš„åŒè‰²çƒæ¨èå·ç å·²æ›´æ–°ï¼ˆ{action}æ¨¡å¼ï¼‰")

        except Exception as e:
            print(f"æ›´æ–°READMEæ¨èå·ç å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    # æ˜¾ç¤ºå…è´£å£°æ˜
    print("=" * 80)
    print(f"ğŸ§° Runtime -> Python: {sys.version.split()[0]} | Torch: {getattr(torch, '__version__', 'N/A')} | CUDA: {torch.cuda.is_available() if hasattr(torch, 'cuda') else False}")
    print(f"ğŸ“„ Running script: {__file__}")
    if sys.version_info < (3, 11):
        print("âš ï¸ å»ºè®®ä½¿ç”¨ Python 3.11+ ä»¥é¿å… macOS LibreSSL/urllib3 è­¦å‘Šï¼Œå¹¶è·å¾—æ›´å¥½çš„ä¾èµ–å…¼å®¹æ€§ã€‚")
    print("ğŸ¯ åŒè‰²çƒæ•°æ®åˆ†æç³»ç»Ÿ")
    print("=" * 80)
    print("âš ï¸  é‡è¦å…è´£å£°æ˜ï¼š")
    print("â€¢ å½©ç¥¨å¼€å¥–å®Œå…¨éšæœºï¼Œå†å²æ•°æ®æ— æ³•é¢„æµ‹æœªæ¥")
    print("â€¢ æœ¬åˆ†æä»…ä¾›å­¦ä¹ å‚è€ƒï¼Œä¸æ„æˆæŠ•æ³¨å»ºè®®")
    print("â€¢ è¯·ç†æ€§è´­å½©ï¼Œé‡åŠ›è€Œè¡Œï¼Œæœªæ»¡18å‘¨å²ç¦æ­¢è´­ä¹°")
    print("â€¢ ä½¿ç”¨æœ¬è½¯ä»¶äº§ç”Ÿçš„ä»»ä½•åæœç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…")
    print("=" * 80)
    
    analyzer = DoubleColorBallAnalyzer()
    
    print("\nåŒè‰²çƒå¼€å¥–æ•°æ®åˆ†æç³»ç»Ÿ")
    print("=" * 50)
    
    # å§‹ç»ˆæŠ“å–æœ€æ–°æ•°æ®ï¼Œè¦†ç›–ç°æœ‰æ–‡ä»¶
    print("âš ï¸  æ­£åœ¨æŠ“å–æœ€æ–°æ•°æ®ï¼Œè¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸...")
    max_pages = analyzer.get_max_pages()
    analyzer.fetch_lottery_data(max_pages=max_pages)
    analyzer.save_data()
    
    if not analyzer.lottery_data:
        print("âŒ æ— æ³•è·å–æ•°æ®ï¼Œç¨‹åºé€€å‡º")
        return
    
    # æ˜¾ç¤ºæ¸¸æˆè§„åˆ™
    analyzer.get_lottery_rules()
    
    # æ‰§è¡Œå„ç§åˆ†æ
    red_counter, blue_counter = analyzer.analyze_frequency()
    analyzer.analyze_patterns()
    analyzer.analyze_trends()
    # è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆLSTMï¼‰
    try:
        analyzer.train_ml_model(seq_len=10, epochs=5, lr=1e-3, hidden_size=64, dropout=0.2)
    except Exception as e:
        print(f"âš ï¸  æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨æ—¶é—´è¡°å‡é¢‘ç‡ä½œä¸ºå¤‡é€‰ã€‚")
        analyzer.trained = False
    print(f"ğŸ§ª æ¨¡å‹è®­ç»ƒçŠ¶æ€: {'å·²è®­ç»ƒ(ä½¿ç”¨LSTMèåˆ)' if analyzer.trained else 'æœªè®­ç»ƒ(ä½¿ç”¨æ—¶é—´è¡°å‡é¢‘ç‡)'}")
    recs = analyzer.generate_recommendations(num_sets=8)
    try:
        analyzer.evaluate_latest_draw(recs)
    except Exception as _e:
        print(f"è¯„ä¼°å½“æœŸå‘½ä¸­æƒ…å†µå¤±è´¥: {_e}")
    # ç”Ÿæˆæ¨èå·ç 
    # recommendations = analyzer.generate_recommendations(num_sets=5)
    
    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    try:
        analyzer.visualize_frequency()
    except Exception as e:
        print(f"âš ï¸  å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
        print("å¯èƒ½æ˜¯å­—ä½“é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿä¸­æ–‡å­—ä½“æ”¯æŒ")
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    analyzer.generate_analysis_report()
    
    # ç”Ÿæˆèšåˆæ•°æ®æ–‡ä»¶
    analyzer.generate_aggregated_data_hjson()
    
    # æ›´æ–°README.mdä¸­çš„æ¨èå·ç 
    analyzer.update_readme_recommendations()
    
    print("\n" + "=" * 50)
    print("ğŸ“‹ é‡è¦æé†’ï¼š")
    print("â€¢ ä»¥ä¸Šæ¨èå·ç åŸºäºå†å²ç»Ÿè®¡ï¼Œä»…ä¾›å‚è€ƒ")
    print("â€¢ å½©ç¥¨å…·æœ‰å¶ç„¶æ€§ï¼Œè¯·å‹¿è¿‡åº¦ä¾èµ–ä»»ä½•é¢„æµ‹")
    print("â€¢ ç†æ€§è´­å½©ï¼Œé€‚åº¦å¨±ä¹ï¼Œçæƒœå®¶åº­å’Œç¦")
    print("â€¢ å¦‚æœ‰èµŒåšé—®é¢˜ï¼Œè¯·å¯»æ±‚ä¸“ä¸šå¸®åŠ©")
    print("=" * 50)
    print("âœ… åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä¾èµ–åº“å®‰è£…æƒ…å†µ") 